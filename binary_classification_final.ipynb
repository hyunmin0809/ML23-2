{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "76OnT99eJAvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24ee5d13-5d76-4332-bc3c-0115e0c768df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz5mat0w2dJy"
      },
      "source": [
        "##Extract features from unmon_standard10.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWfcIOZovSMl",
        "outputId": "47da5553-ac6f-4cb3-d616-6c2bb30a3eee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datafile...\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "TOTAL_URLS = 10000  # total number in the dataset\n",
        "\n",
        "# Load 10,000 unmon pickle file\n",
        "print(\"Loading datafile...\")\n",
        "with open('/content/drive/MyDrive/unmon_standard10.pkl', 'rb') as f:  # Path to unmon_standard10.pkl in Colab\n",
        "    x = pickle.load(f)\n",
        "\n",
        "size = len(x)\n",
        "print(f'Total samples: {size}')\n",
        "\n",
        "# X1 ~ X4\n",
        "X1_unmon = [] # Array to store instances (timestamps) - 10,000 instances, e.g., [[0.0, 0.5, 3.4, ...], [0.0, 4.5, ...], [0.0, 1.5, ...], ... [... ,45.8]]\n",
        "#X2 = [] # Array to store instances (direction*size) - size information\n",
        "\n",
        "#X3 = [] # Array to store bursts - 10,000 instances\n",
        "#X4 = [] # Array to store cumulative packet sizes - 10,000 instances\n",
        "\n",
        "#X5 ~ X17: Categorical features(13개)\n",
        "         # Arrays to store ~\n",
        "X5_unmon = []  # rank 1.Number of incoming packets\n",
        "X6_unmon = []  # rank 2.Number of outgoing packets as a fraction of the total number of packets\n",
        "X7_unmon = []  # rank 3.Number of incoming packets as a fraction of the total number of packets\n",
        "# X8 = []  # rank 4.Standard deviation of the outgoing packet ordering list\n",
        "X9_unmon = []  # rank 5.Number of outgoing packets\n",
        "# X10 = [] # rank 6.Sum of all items in the alternative concentration feature list\n",
        "# X11 = [] # rank 7.Average of the outgoing packet ordering list\n",
        "X12_unmon = [] # rank 8.Sum of incoming, outgoing and total number of packets\n",
        "# X13 = [] # rank 9.Sum of alternative number packets per second\n",
        "X14_unmon = [] # rank 10.Total number of packets\n",
        "#          # X15 ~ X17: Packet concentration and ordering features list\n",
        "# X15 = [] # rank 11.Mean of the number of outgoing packets in chunks of 20 packets\n",
        "# X16 = [] # rank 12.Standard deviation of the incoming packet ordering list\n",
        "# X17 = [] # rank 13.Average of the incoming packet ordering list\n",
        "\n",
        "\n",
        "# Differentiate instances and sites, and store them in the respective x and y arrays\n",
        "# x array (direction*timestamp), y array (site label)\n",
        "for i in range(TOTAL_URLS):\n",
        "      label = -1\n",
        "      time_seq = [] #X1\n",
        "      incoming_count = 0 #X5\n",
        "      outgoing_fraction = 0.0 #X6\n",
        "      outgoing_count = 0 #X9\n",
        "      incoming_fraction = 0.0 #X7\n",
        "      packet_sum = [] #X12\n",
        "\n",
        "      burst_sum = 0\n",
        "      last_sign = None\n",
        "      cumulative_sum = 0\n",
        "\n",
        "      for c in x[i]:\n",
        "          dr = 1 if c > 0 else -1\n",
        "\n",
        "          if c > 0:\n",
        "            outgoing_count += 1\n",
        "          else:\n",
        "            sign = -1\n",
        "            incoming_count += 1 # X5\n",
        "\n",
        "      #X1\n",
        "      differences = [abs(x[i][k+1])-abs(x[i][k]) for k in range(len(x[i])-1)]\n",
        "      average_diff = sum(differences) / len(differences)\n",
        "      time_seq=average_diff\n",
        "\n",
        "      #X6 (rank 2), X7 (rank 3)\n",
        "      total_packets = len(x[i])\n",
        "      if total_packets > 0:\n",
        "          outgoing_fraction = outgoing_count / total_packets #X6\n",
        "          incoming_fraction = incoming_count / total_packets #X7\n",
        "\n",
        "      # X12(rank 8)\n",
        "      packet_sum = outgoing_count + incoming_count + total_packets\n",
        "\n",
        "      # X14(rank 10)\n",
        "      total_packets_num = len(x[i])\n",
        "\n",
        "      X1_unmon.append(time_seq)\n",
        "      X5_unmon.append(incoming_count)\n",
        "      X6_unmon.append(outgoing_fraction)\n",
        "      X7_unmon.append(incoming_fraction)\n",
        "      X9_unmon.append(outgoing_count)\n",
        "      X12_unmon.append(packet_sum)\n",
        "      X14_unmon.append(total_packets_num)\n",
        "\n",
        "\n",
        "size = (len(X1_unmon)) # Print the length of X1\n",
        "\n",
        "\n",
        "print(f'Total samples: {size}')\n",
        "\n",
        "# Print the first 10 entries in X1, X2, and y\n",
        "for i in range(0, 10):\n",
        "    print(f\"Sample {i + 1}:\")\n",
        "    print(\"X1_unmon:\", X1_unmon[i])\n",
        "    print(\"X5_unmon:\", X5_unmon[i])\n",
        "    print(\"X6_unmon:\", X6_unmon[i])\n",
        "    print(\"X7_unmon:\", X7_unmon[i])\n",
        "    print(\"X9_unmon:\", X9_unmon[i])\n",
        "    print(\"X12_unmon:\", X12_unmon[i])\n",
        "    print(\"X14_unmon:\", X14_unmon[i])\n",
        "    print(\"-\" * 20)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get monitored data(feature has already extracted, its content is features.)"
      ],
      "metadata": {
        "id": "IfqtK5AIvGhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "DSB10rcltx18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "cOiKp1pZ739q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X, y data\n",
        "file_path_1 = '/content/drive/My Drive/data_arrays_1.npz'\n",
        "file_path_2 = '/content/drive/My Drive/data_arrays_2.npz'\n",
        "file_path_3 = '/content/drive/My Drive/data_arrays_3.npz'\n",
        "file_path_4 = '/content/drive/My Drive/data_arrays_4.npz'\n",
        "file_path_5 = '/content/drive/My Drive/y_values.npy'\n",
        "\n",
        "# read npz file (added 'allow_pickle=True' option)\n",
        "data_1 = np.load(file_path_1, allow_pickle=True)\n",
        "data_2 = np.load(file_path_2, allow_pickle=True)\n",
        "data_3 = np.load(file_path_3, allow_pickle=True)\n",
        "data_4 = np.load(file_path_4, allow_pickle=True)\n",
        "\n",
        "# extract X data\n",
        "data_y = {'0': [1] * 19000}\n",
        "y_mon = pd.DataFrame(data_y)\n",
        "X1_mon = data_1['X1']\n",
        "X5_mon = data_2['X5']\n",
        "X6_mon = data_2['X6']\n",
        "X7_mon = data_2['X7']\n",
        "X9_mon = data_3['X9']\n",
        "X12_mon = data_3['X12']\n",
        "X14_mon = data_4['X14']\n",
        "\n",
        "data_mon = pd.DataFrame({\n",
        "    'Feature1': X1_mon,\n",
        "    'Feature5': X5_mon,\n",
        "    'Feature6': X6_mon,\n",
        "    'Feature7': X7_mon,\n",
        "    'Feature9': X9_mon,\n",
        "    'Feature12': X12_mon,\n",
        "    'Feature14': X14_mon,\n",
        "})"
      ],
      "metadata": {
        "id": "zHJ_8ic8vPLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mon = pd.DataFrame(data_mon)\n",
        "df_mon"
      ],
      "metadata": {
        "id": "5USGlvPDvpI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize monitored data\n",
        "df_mon.plot(y = ['Feature1'])\n",
        "df_mon.plot(y = ['Feature5'])\n",
        "df_mon.plot(y = ['Feature6'])\n",
        "df_mon.plot(y = ['Feature7'])\n",
        "df_mon.plot(y = ['Feature9'])\n",
        "df_mon.plot(y = ['Feature12'])\n",
        "df_mon.plot(y = ['Feature14'])"
      ],
      "metadata": {
        "id": "-r_qgh4M8EAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_y_mon = pd.DataFrame(y_mon)\n",
        "df_y_mon"
      ],
      "metadata": {
        "id": "HGRLWOzFvxEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##unmonitored feature datas into dataframe"
      ],
      "metadata": {
        "id": "wHK2D4m7uNi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_unmon = pd.DataFrame({\n",
        "    'Feature1': X1_unmon,\n",
        "    'Feature5': X5_unmon,\n",
        "    'Feature6': X6_unmon,\n",
        "    'Feature7': X7_unmon,\n",
        "    'Feature9': X9_unmon,\n",
        "    'Feature12': X12_unmon,\n",
        "    'Feature14': X14_unmon\n",
        "})"
      ],
      "metadata": {
        "id": "SNvxJP5etifN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_y_unmon = {'0': [-1] * 10000}\n",
        "y_unmon = pd.DataFrame(data_y_unmon)"
      ],
      "metadata": {
        "id": "KeYblwV12AlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_unmon = pd.DataFrame(data_unmon)\n",
        "df_unmon"
      ],
      "metadata": {
        "id": "4i0VkK6CuD8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize unmonitored data\n",
        "df_unmon.plot(y = ['Feature1'])\n",
        "df_unmon.plot(y = ['Feature5'])\n",
        "df_unmon.plot(y = ['Feature6'])\n",
        "df_unmon.plot(y = ['Feature7'])\n",
        "df_unmon.plot(y = ['Feature9'])\n",
        "df_unmon.plot(y = ['Feature12'])\n",
        "df_unmon.plot(y = ['Feature14'])"
      ],
      "metadata": {
        "id": "SZr3YAYh9QVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_y_unmon = pd.DataFrame(y_unmon)\n",
        "df_y_unmon"
      ],
      "metadata": {
        "id": "tzoTBPN8uG6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##make total data set: unmon + mon"
      ],
      "metadata": {
        "id": "rLZTb81rwuQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_total = pd.concat([df_unmon, df_mon])"
      ],
      "metadata": {
        "id": "2xDe5RwIwt-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_total"
      ],
      "metadata": {
        "id": "f8fnOiNhyH4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_y_total = pd.concat([df_y_unmon, df_y_mon])"
      ],
      "metadata": {
        "id": "_Gd6DZZNxWQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_y_total"
      ],
      "metadata": {
        "id": "lMjKtE0iyOxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "87IiNxwW2tC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###split dataset train:test=80:20"
      ],
      "metadata": {
        "id": "PkR1xJoZEqTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = data_total\n",
        "y = data_y_total\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=1\n",
        ")"
      ],
      "metadata": {
        "id": "WW3GTcV52pCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Logistic Regression"
      ],
      "metadata": {
        "id": "7loMXNscpVHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, classification_report\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "-Ttr40XW3H-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_LR = LogisticRegression(max_iter=5000)\n",
        "clf_LR.fit(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "nYR8yrOl3Kvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_LR.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "4JScQ7043MfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict test data\n",
        "y_pred_lr = clf_LR.predict(X_test)"
      ],
      "metadata": {
        "id": "w_DBczykCi6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression evaluation\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "recall_lr = recall_score(y_test, y_pred_lr)\n",
        "precision_lr = precision_score(y_test, y_pred_lr)\n",
        "f1_lr = f1_score(y_test, y_pred_lr)\n",
        "f1_macro_lr = f1_score(y_test, y_pred_lr, average='macro')\n",
        "f1_weighted_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
        "\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_lr)\n",
        "print(\"Logistic Regression Recall:\", recall_lr)\n",
        "print(\"Logistic Regression Precision:\", precision_lr)\n",
        "print(\"Logistic Regression f1 score:\", f1_lr)\n",
        "print(\"Logistic Regression macro average:\", f1_macro_lr)\n",
        "print(\"Logistic Regression weighted average:\", f1_weighted_lr)\n",
        "print()\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_lr))"
      ],
      "metadata": {
        "id": "2xtJm8MiS0oC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Logistic Regression hyperparameter tuning"
      ],
      "metadata": {
        "id": "QAKQidlznVBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "4Cb9BhsLn3I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression_model = LogisticRegression()"
      ],
      "metadata": {
        "id": "qdAMGuH8oT7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_LR = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}"
      ],
      "metadata": {
        "id": "R7tN_HpznfzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_1 = GridSearchCV(logistic_regression_model, param_grid_LR, cv=5, scoring='accuracy')\n",
        "grid_search_1.fit(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "hAMFOapJnqJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Parameters:\", grid_search_1.best_params_)"
      ],
      "metadata": {
        "id": "WfwPn7sbolbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_logistic_regression_model = grid_search_1.best_estimator_\n",
        "y_pred_CV1 = best_logistic_regression_model.predict(X_test) # y_pred_CrossValidation1(LR)"
      ],
      "metadata": {
        "id": "kqpEZ_zioqTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation\n",
        "accuracy_CV1 = accuracy_score(y_test, y_pred_CV1)\n",
        "recall_CV1 = recall_score(y_test, y_pred_CV1)\n",
        "precision_CV1 = precision_score(y_test, y_pred_CV1)\n",
        "f1_CV1 = f1_score(y_test, y_pred_CV1)\n",
        "f1_macro_CV1 = f1_score(y_test, y_pred_CV1, average='macro')\n",
        "f1_weighted_CV1 = f1_score(y_test, y_pred_CV1, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy_CV1}\")\n",
        "print(f\"Precision: {precision_CV1}\")\n",
        "print(f\"Recall: {recall_CV1}\")\n",
        "print(f\"F1 score: {f1_CV1}\")\n",
        "print(f\"Macro average score: {f1_macro_CV1}\")\n",
        "print(f\"Weighted average score: {f1_weighted_CV1}\")\n",
        "print()\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_CV1))"
      ],
      "metadata": {
        "id": "jz54euCJovQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Linear SVM"
      ],
      "metadata": {
        "id": "m9Bj6dA5pY9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC, SVC"
      ],
      "metadata": {
        "id": "kuFc2oeCij-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LinearSVC\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "clf_SVM = LinearSVC(C=10000, loss='hinge')\n",
        "clf_SVM.fit(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "wTBWC3az3Reg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lsvm = clf_SVM.predict(X_test)"
      ],
      "metadata": {
        "id": "a5qSQPCf3T7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear SVM 모델 성능 평가\n",
        "accuracy_lsvm = accuracy_score(y_test, y_pred_lsvm)\n",
        "recall_lsvm = recall_score(y_test, y_pred_lsvm)\n",
        "precision_lsvm = precision_score(y_test, y_pred_lsvm)\n",
        "f1_lsvm = f1_score(y_test, y_pred_lsvm)\n",
        "f1_macro_lsvm = f1_score(y_test, y_pred_lsvm, average='macro')\n",
        "f1_weighted_lsvm = f1_score(y_test, y_pred_lsvm, average='weighted')\n",
        "\n",
        "print(\"Linear SVM Accuracy:\", accuracy_lsvm)\n",
        "print(\"Linear SVM Recall:\", recall_lsvm)\n",
        "print(\"Linear SVM Precision:\", precision_lsvm)\n",
        "print(\"Linear SVM f1 score:\", f1_lsvm)\n",
        "print(\"Linear SVM macro average:\", f1_macro_lsvm)\n",
        "print(\"Linear SVM weighted average:\", f1_weighted_lsvm)\n",
        "print()\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_lsvm))"
      ],
      "metadata": {
        "id": "8Fo-TmpE3Wor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Linear SVM hyperparameter tuning"
      ],
      "metadata": {
        "id": "6doTeRZxqmpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_svm_model = SVC(kernel='linear')\n",
        "param_grid_LSVM = {'C': [0.1, 1, 10, 100]}"
      ],
      "metadata": {
        "id": "YP-ogrMsqp55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_2 = GridSearchCV(linear_svm_model, param_grid_LSVM, cv=2, scoring='accuracy')\n",
        "grid_search_2.fit(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "ctE7Di3xq6tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Parameters:\", grid_search_2.best_params_)"
      ],
      "metadata": {
        "id": "KXG8u3jLrHGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_linear_svm_model = grid_search_2.best_estimator_\n",
        "y_pred_CV2 = best_linear_svm_model.predict(X_test)"
      ],
      "metadata": {
        "id": "8O5eC1i_IMqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation\n",
        "accuracy_CV2 = accuracy_score(y_test, y_pred_CV2)\n",
        "recall_CV2 = recall_score(y_test, y_pred_CV2)\n",
        "precision_CV2 = precision_score(y_test, y_pred_CV2)\n",
        "f1_CV2 = f1_score(y_test, y_pred_CV2)\n",
        "f1_macro_CV2 = f1_score(y_test, y_pred_CV2, average='macro')\n",
        "f1_weighted_CV2 = f1_score(y_test, y_pred_CV2, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy_CV1}\")\n",
        "print(f\"Precision: {precision_CV1}\")\n",
        "print(f\"Recall: {recall_CV1}\")\n",
        "print(f\"F1 score: {f1_CV1}\")\n",
        "print(f\"Macro average score: {f1_macro_CV2}\")\n",
        "print(f\"Weighted average score: {f1_weighted_CV2}\")\n",
        "print()\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_CV2))"
      ],
      "metadata": {
        "id": "smKSPIhrVGSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. SVM with RBF"
      ],
      "metadata": {
        "id": "YRC5XLW6rlca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVC\n",
        "clf_SVM_rbf = SVC(kernel = 'rbf', random_state = 0, C=100000)\n",
        "clf_SVM_rbf.fit(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "e0NcDCP73YG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_svm = clf_SVM_rbf.predict(X_test)"
      ],
      "metadata": {
        "id": "7OZtGp8b3am7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM evaluation\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "recall_svm = recall_score(y_test, y_pred_svm)\n",
        "precision_svm = precision_score(y_test, y_pred_svm)\n",
        "f1_svm = f1_score(y_test, y_pred_svm)\n",
        "f1_macro_svm = f1_score(y_test, y_pred_svm, average='macro')\n",
        "f1_weighted_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
        "\n",
        "print(\"SVM Accuracy:\", accuracy_svm)\n",
        "print(\"SVM Recall:\", recall_svm)\n",
        "print(\"SVM Precision:\", precision_svm)\n",
        "print(\"SVM f1 score:\", f1_svm)\n",
        "print(\"SVM macro average:\", f1_macro_svm)\n",
        "print(\"SVM weighted average:\", f1_weighted_svm)\n",
        "print()\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_svm))"
      ],
      "metadata": {
        "id": "0vpuCmiM3g5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SVM with RBF hyperparameter tuning"
      ],
      "metadata": {
        "id": "D2wquACxvJFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_rbf_model = SVC(kernel='rbf')\n",
        "param_grid_svm_rbf = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "                      'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}"
      ],
      "metadata": {
        "id": "Gpj3GATUvM8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_3 = GridSearchCV(svm_rbf_model, param_grid_svm_rbf, cv=2, scoring='accuracy')\n",
        "grid_search_3.fit(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "ZjVftH-fvUty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Parameters:\", grid_search_3.best_params_)"
      ],
      "metadata": {
        "id": "3GzN-VvRveH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_svm_rbf_model = grid_search_3.best_estimator_\n",
        "y_pred_CV3 = best_svm_rbf_model.predict(X_test)"
      ],
      "metadata": {
        "id": "epUqVgjivhtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation\n",
        "accuracy_CV3 = accuracy_score(y_test, y_pred_CV3)\n",
        "recall_CV3 = recall_score(y_test, y_pred_CV3)\n",
        "precision_CV3 = precision_score(y_test, y_pred_CV3)\n",
        "f1_CV3 = f1_score(y_test, y_pred_CV3)\n",
        "f1_macro_CV3 = f1_score(y_test, y_pred_CV3, average='macro')\n",
        "f1_weighted_CV3 = f1_score(y_test, y_pred_CV3, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy_CV3}\")\n",
        "print(f\"Precision: {precision_CV3}\")\n",
        "print(f\"Recall: {recall_CV3}\")\n",
        "print(f\"F1 score: {f1_CV3}\")\n",
        "print(f\"Macro average score: {f1_macro_CV3}\")\n",
        "print(f\"Weighted average score: {f1_weighted_CV3}\")\n",
        "print()\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_CV3))"
      ],
      "metadata": {
        "id": "VYSUBNk1V3iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Naive Bayes"
      ],
      "metadata": {
        "id": "skqXTZPowKZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, classification_report\n",
        "\n",
        "# Naive Bayes model\n",
        "clf_nb = GaussianNB()\n",
        "\n",
        "# train\n",
        "clf_nb.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "kTrjvRCCor2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test data prediction\n",
        "y_pred_nb = clf_nb.predict(X_test)"
      ],
      "metadata": {
        "id": "YM9Sk6blxtct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes evaluation\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "recall_nb = recall_score(y_test, y_pred_nb)\n",
        "precision_nb = precision_score(y_test, y_pred_nb)\n",
        "f1_nb = f1_score(y_test, y_pred_nb)\n",
        "f1_macro_nb = f1_score(y_test, y_pred_nb, average='macro')\n",
        "f1_weighted_nb = f1_score(y_test, y_pred_nb, average='weighted')\n",
        "\n",
        "print(\"Naive Bayes Accuracy:\", accuracy_nb)\n",
        "print(\"Naive Bayes Recall:\", recall_nb)\n",
        "print(\"Naive Bayes Precision:\", precision_nb)\n",
        "print(\"Naive Bayes f1 score:\", f1_nb)\n",
        "print(\"Naive Bayes macro average:\", f1_macro_nb)\n",
        "print(\"Naive Bayes weighted average:\", f1_weighted_nb)\n",
        "print()\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_nb))"
      ],
      "metadata": {
        "id": "qgwUPEeXWQ8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Decision Tree"
      ],
      "metadata": {
        "id": "ZbPF0MYLwffQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "I9oePxa5mxCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree model\n",
        "clf_dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# train\n",
        "clf_dt.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "hEnJV5mGqqa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test prediction\n",
        "y_pred_dt = clf_dt.predict(X_test)"
      ],
      "metadata": {
        "id": "J4Zndg5yxyz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree evaluation\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "recall_dt = recall_score(y_test, y_pred_dt)\n",
        "precision_dt = precision_score(y_test, y_pred_dt)\n",
        "f1_dt = f1_score(y_test, y_pred_dt)\n",
        "f1_macro_dt = f1_score(y_test, y_pred_dt, average='macro')\n",
        "f1_weighted_dt = f1_score(y_test, y_pred_dt, average='weighted')\n",
        "\n",
        "print(\"Decision Tree Accuracy:\", accuracy_dt)\n",
        "print(\"Decision Tree Recall:\", recall_dt)\n",
        "print(\"Decision Tree Precision:\", precision_dt)\n",
        "print(\"Decision Tree f1 score:\", f1_dt)\n",
        "print(\"Decision Tree macro average:\", f1_macro_dt)\n",
        "print(\"Decision Tree weighted average:\", f1_weighted_dt)\n",
        "print()\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_dt))"
      ],
      "metadata": {
        "id": "oLeBWPsqW6QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Decision Tree hyperparameter tuning"
      ],
      "metadata": {
        "id": "7QljTCIZwmCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree_model = DecisionTreeClassifier()\n",
        "param_grid_decision_tree = {'max_depth': [None, 10, 20, 30, 40, 50]}"
      ],
      "metadata": {
        "id": "zb5KI_-Cwo1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_4 = GridSearchCV(decision_tree_model, param_grid_decision_tree, cv=5, scoring='accuracy')\n",
        "grid_search_4.fit(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "rWG4n6Dkwwul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Parameters:\", grid_search_4.best_params_)"
      ],
      "metadata": {
        "id": "JdtFgCmPw-M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_decision_tree_model = grid_search_4.best_estimator_\n",
        "y_pred_CV4 = best_decision_tree_model.predict(X_test)\n",
        "accuracy_CV4 = accuracy_score(y_test, y_pred_CV4)\n",
        "precision_CV4 = precision_score(y_test, y_pred_CV4)\n",
        "recall_CV4 = recall_score(y_test, y_pred_CV4)"
      ],
      "metadata": {
        "id": "_Qal8pOGxBuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {accuracy_CV4}\")\n",
        "print(f\"Precision: {precision_CV4}\")\n",
        "print(f\"Recall: {recall_CV4}\")"
      ],
      "metadata": {
        "id": "f1sIRzMJxTHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_CV4 = accuracy_score(y_test, y_pred_CV4)\n",
        "recall_CV4 = recall_score(y_test, y_pred_CV4)\n",
        "precision_CV4 = precision_score(y_test, y_pred_CV4)\n",
        "f1_CV4 = f1_score(y_test, y_pred_CV4)\n",
        "f1_macro_CV4 = f1_score(y_test, y_pred_CV4, average='macro')\n",
        "f1_weighted_CV4 = f1_score(y_test, y_pred_CV4, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy_CV4}\")\n",
        "print(f\"Precision: {precision_CV4}\")\n",
        "print(f\"Recall: {recall_CV4}\")\n",
        "print(f\"F1 score: {f1_CV4}\")\n",
        "print(f\"Macro average score: {f1_macro_CV4}\")\n",
        "print(f\"Weighted average score: {f1_weighted_CV4}\")\n",
        "print()\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_CV4))"
      ],
      "metadata": {
        "id": "eL7aZ2IVXgRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overall model evaluation"
      ],
      "metadata": {
        "id": "cs_srecfsjUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models_graph = ['Linear Regression', 'Linear SVM', 'SVM', 'Naive Bayes', 'Decision Tree']"
      ],
      "metadata": {
        "id": "LHMRD_ZFspLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = [0.65, 0.65, 0.67, 0.63, 0.70]\n",
        "precisions = [0.57, 0.61, 0.63, 0.56, 0.67]\n",
        "recalls = [0.50, 0.53, 0.57, 0.54, 0.62]\n",
        "f1_scores = [0.39, 0.47, 0.56, 0.53, 0.63]"
      ],
      "metadata": {
        "id": "uqXn_7-6s4wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12,10))\n",
        "\n",
        "bar_width = 0.2\n",
        "indices = np.arange(len(models_graph))\n",
        "\n",
        "# Accuracy\n",
        "ax.bar(indices - 1.5 * bar_width, accuracies, bar_width, color='blue', label='Accuracy')\n",
        "\n",
        "# Precision\n",
        "ax.bar(indices - 0.5 * bar_width, precisions, bar_width, color='green', label='Precision')\n",
        "\n",
        "# Recall\n",
        "ax.bar(indices + 0.5 * bar_width, recalls, bar_width, color='orange', label='Recall')\n",
        "\n",
        "# F1 Score\n",
        "ax.bar(indices + 1.5 * bar_width, f1_scores, bar_width, color='red', label='F1 Score')\n",
        "\n",
        "ax.set_xticks(indices)\n",
        "ax.set_xticklabels(models_graph)\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_title('Model Performance Comparison-Macro average')\n",
        "ax.legend()\n",
        "\n",
        "# 레이아웃 조정\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0mvWAXoFtSIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = [0.65, 0.65, 0.67, 0.63, 0.70]\n",
        "precisions = [0.59, 0.62, 0.64, 0.59, 0.69]\n",
        "recalls = [0.65, 0.65, 0.67, 0.63, 0.70]\n",
        "f1_scores = [0.51, 0.56, 0.62, 0.59, 0.67]"
      ],
      "metadata": {
        "id": "RV3qb-MRto1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "bar_width = 0.2\n",
        "indices = np.arange(len(models_graph))\n",
        "\n",
        "# Accuracy\n",
        "ax.bar(indices - 1.5 * bar_width, accuracies, bar_width, color='blue', label='Accuracy')\n",
        "\n",
        "# Precision\n",
        "ax.bar(indices - 0.5 * bar_width, precisions, bar_width, color='green', label='Precision')\n",
        "\n",
        "# Recall\n",
        "ax.bar(indices + 0.5 * bar_width, recalls, bar_width, color='orange', label='Recall')\n",
        "\n",
        "# F1 Score\n",
        "ax.bar(indices + 1.5 * bar_width, f1_scores, bar_width, color='red', label='F1 Score')\n",
        "\n",
        "ax.set_xticks(indices)\n",
        "ax.set_xticklabels(models_graph)\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_title('Model Performance Comparison-weight average')\n",
        "ax.legend()\n",
        "\n",
        "# 레이아웃 조정\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "276TShpTuMH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##unmon 데이터 binary classification 하기"
      ],
      "metadata": {
        "id": "KFhSOM4kf-eT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Decision Tree(Best)"
      ],
      "metadata": {
        "id": "wRIkyJMI5oVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_DT = best_decision_tree_model.predict(df_unmon)"
      ],
      "metadata": {
        "id": "DVq5bRR05p9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_DT"
      ],
      "metadata": {
        "id": "-J-sbfFC5wz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(range(len(predict_DT)), predict_DT)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zq0GhvRl_2kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Linear Regression"
      ],
      "metadata": {
        "id": "zkib1QF93u_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_LR = best_logistic_regression_model.predict(df_unmon)"
      ],
      "metadata": {
        "id": "TyuBrG7J2G3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_LR"
      ],
      "metadata": {
        "id": "CqdmWCTg3KQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(range(len(predict_LR)), predict_LR)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9AdrzMTY-D-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LinearSVC"
      ],
      "metadata": {
        "id": "k3eUd2QF3xY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_LSVC = best_linear_svm_model.predict(df_unmon)"
      ],
      "metadata": {
        "id": "GG3MQOpf4nL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_LSVC"
      ],
      "metadata": {
        "id": "UO2ur52I436j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(range(len(predict_LSVC)), predict_LSVC)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9MLZzEpl_a0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SVC with RBF"
      ],
      "metadata": {
        "id": "4NBqBCKC4-6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_SVC = best_svm_rbf_model.predict(df_unmon)"
      ],
      "metadata": {
        "id": "L0BVkZj85BNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_SVC"
      ],
      "metadata": {
        "id": "hqWZ5RkvIkD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(range(len(predict_SVC)), predict_SVC)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "29JmRPx0_kSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Naive Bayes"
      ],
      "metadata": {
        "id": "jB82Y4wo5T_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_NB = clf_nb.predict(df_unmon)"
      ],
      "metadata": {
        "id": "TUMg73mz5dun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_NB"
      ],
      "metadata": {
        "id": "v9s_Nf8i5l6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(range(len(predict_NB)), predict_NB)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AzdX0gmi_wln"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}