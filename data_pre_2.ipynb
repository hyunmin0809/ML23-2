{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUfUv4C-byZU"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "USE_SUBLABEL = False\n",
        "URL_PER_SITE = 10\n",
        "TOTAL_URLS   = 950\n",
        "\n",
        "# Load the pickle file\n",
        "print(\"Loading datafile...\")\n",
        "with open(\"/content/drive/MyDrive/mon_standard.pkl\", 'rb') as fi: #Colab 에서 mon_standard.pkl 파일의 경로\n",
        "    data = pickle.load(fi)\n",
        "\n",
        "# X1 ~ X4: Continuous features(4개)\n",
        "\n",
        "X4 = [] # Array to store cumulative packet sizes - 19,000 instances\n",
        "\n",
        "#X5 ~ X17: Categorical features(13개)\n",
        "         # Arrays to store ~\n",
        "X5 = []  # rank 1.Number of incoming packets\n",
        "X6 = []  # rank 2.Number of outgoing packets as a fraction of the total number of packets\n",
        "X7 = []  # rank 3.Number of incoming packets as a fraction of the total number of packets\n",
        "\n",
        "y = []  # Array to store the site of each instance - 19,000 instances, e.g., [0, 0, 0, 0, 0, 0, ..., 94, 94, 94, 94, 94]\n",
        "\n",
        "\n",
        "# Differentiate instances and sites, and store them in the respective x and y arrays\n",
        "# x array (direction*timestamp), y array (site label)\n",
        "for i in range(TOTAL_URLS):\n",
        "    if USE_SUBLABEL:\n",
        "        label = i\n",
        "    else:\n",
        "        label = i // URL_PER_SITE # Calculate which site's URL the current URL being processed belongs to and set that value as the label. Thus, URLs fetched from the same site are labeled identically.\n",
        "\n",
        "    for sample in data[i]:\n",
        "        size_seq = [] #X2\n",
        "        size_cumulative_seq = [] #X4\n",
        "        outgoing_count = 0\n",
        "        incoming_count = 0 #X5\n",
        "        outgoing_fraction = 0.0 #X6\n",
        "        incoming_fraction = 0.0 #X7\n",
        "\n",
        "        last_sign = None\n",
        "        cumulative_sum = 0\n",
        "\n",
        "        for c in sample:\n",
        "\n",
        "            # Calculate the direction and size for packet size\n",
        "            dr = 1 if c > 0 else -1\n",
        "            packet_size = dr * 512\n",
        "\n",
        "           # X3\n",
        "           # Calculate the burst sequence based on the sign of the value\n",
        "            if c > 0:\n",
        "                sign = 1\n",
        "                outgoing_count += 1 #X6 (rank 1)\n",
        "\n",
        "            else:\n",
        "                sign = -1\n",
        "                incoming_count += 1 #X5 (rank 1)\n",
        "\n",
        "            last_sign = sign\n",
        "\n",
        "            #X4\n",
        "            cumulative_sum += packet_size\n",
        "            size_cumulative_seq.append(cumulative_sum)\n",
        "\n",
        "\n",
        "        #X6 (rank 2), X7 (rank 3)\n",
        "        total_packets = len(sample)\n",
        "        if total_packets > 0:\n",
        "            outgoing_fraction = outgoing_count / total_packets #X6\n",
        "            incoming_fraction = incoming_count / total_packets #X7\n",
        "\n",
        "\n",
        "\n",
        "        X4.append(size_cumulative_seq)\n",
        "        X5.append(incoming_count)\n",
        "        X6.append(outgoing_fraction)\n",
        "        X7.append(incoming_fraction)\n",
        "\n",
        "        y.append(label)\n",
        "\n",
        "X4_np = np.array([np.array(xi) for xi in X4])\n",
        "X5_np = np.array([np.array(xi) for xi in X5])\n",
        "X6_np = np.array([np.array(xi) for xi in X6])\n",
        "X7_np = np.array([np.array(xi) for xi in X7])\n",
        "\n",
        "size = len(y)\n",
        "\n",
        "# Extract y values and remove duplicates\n",
        "unique_y = list(set(y))\n",
        "\n",
        "y_np = np.array(y)\n",
        "\n",
        "\n",
        "np.savez('/content/drive/MyDrive/data_2_np_array.npz', X4=X4_np, X5=X5_np, X6=X6_np, X7=X7_np, y=y_np)\n",
        "\n"
      ],
      "metadata": {
        "id": "8gM7RUllb3DO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}