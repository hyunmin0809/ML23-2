{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz5mat0w2dJy"
      },
      "source": [
        "unmon_standard10.pkl > array code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76OnT99eJAvZ",
        "outputId": "b272c88f-b37d-4665-d931-5d5ae905f91c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfqtK5AIvGhL"
      },
      "source": [
        "## 1. 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHJ_8ic8vPLf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# X와 y 데이터 불러오기\n",
        "file_path_1 = '/content/drive/My Drive/dataset/feature/data_arrays_1.npz'\n",
        "file_path_2 = '/content/drive/My Drive/dataset/feature/data_arrays_2.npz'\n",
        "file_path_3 = '/content/drive/My Drive/dataset/feature/data_arrays_3.npz'\n",
        "file_path_4 = '/content/drive/My Drive/dataset/feature/data_arrays_4.npz'\n",
        "file_path_5 = '/content/drive/My Drive/dataset/feature/unmon_data_1.npz'\n",
        "file_path_6 = '/content/drive/My Drive/dataset/feature/unmon_data_2.npz'\n",
        "\n",
        "# npz 파일 읽기 (allow_pickle=True 옵션 추가)\n",
        "data_1 = np.load(file_path_1, allow_pickle=True)\n",
        "data_2 = np.load(file_path_2, allow_pickle=True)\n",
        "data_3 = np.load(file_path_3, allow_pickle=True)\n",
        "data_4 = np.load(file_path_4, allow_pickle=True)\n",
        "\n",
        "#이 밑에서부터는 unmon\n",
        "data_5 = np.load(file_path_5, allow_pickle=True) #X1, X5, X6, X7, X9, X12, X14의 정보를 담고 있다\n",
        "data_6 = np.load(file_path_6, allow_pickle=True) #X3, X5, X8, X11, X15, X116, X17의 정보를 담고 있다\n",
        "\n",
        "# X 데이터 추출\n",
        "# y = data_1['y']\n",
        "y_mon = data_1['y']\n",
        "X1_mon = data_1['X1']\n",
        "X3_mon = data_1['X3']\n",
        "X5_mon = data_2['X5']  # X1 데이터 로드\n",
        "X6_mon = data_2['X6']\n",
        "X7_mon = data_2['X7']\n",
        "X8_mon = data_3['X8']\n",
        "X9_mon = data_3['X9']\n",
        "X11_mon = data_3['X11']\n",
        "X12_mon = data_3['X12']  # X1 데이터 로드\n",
        "X14_mon = data_4['X14']\n",
        "X15_mon = data_4['X15']\n",
        "X16_mon = data_4['X16']\n",
        "X17_mon = data_4['X17']\n",
        "\n",
        "X1_unmon = data_5['X1_unmon']\n",
        "X5_unmon = data_5['X5_unmon']  # X1 데이터 로드\n",
        "X6_unmon = data_5['X6_unmon']\n",
        "X7_unmon = data_5['X7_unmon']\n",
        "X9_unmon = data_5['X9_unmon']\n",
        "X12_unmon = data_5['X12_unmon']  # X1 데이터 로드\n",
        "X14_unmon = data_5['X14_unmon']\n",
        "\n",
        "X3_unmon = data_6['X3']\n",
        "X8_unmon = data_6['X8']\n",
        "X11_unmon = data_6['X11']\n",
        "X15_unmon = data_6['X15']\n",
        "X16_unmon = data_6['X16']\n",
        "X17_unmon = data_6['X17']\n",
        "\n",
        "data_mon = pd.DataFrame({\n",
        "    'Feature1': X1_mon,\n",
        "    'Feature3': X3_mon,\n",
        "    'Feature5': X5_mon,\n",
        "    'Feature6': X6_mon,\n",
        "    'Feature7': X7_mon,\n",
        "    'Feature8': X8_mon,\n",
        "    'Feature9': X9_mon,\n",
        "    #'Feature11': X11_mon,\n",
        "    'Feature12': X12_mon,\n",
        "    'Feature14': X14_mon,\n",
        "    #'Feature15': X15_mon,\n",
        "    'Feature16': X16_mon,\n",
        "    #'Feature17': X17_mon\n",
        "})\n",
        "\n",
        "data_unmon = pd.DataFrame({\n",
        "    'Feature1': X1_unmon,\n",
        "    'Feature3': X3_unmon,\n",
        "    'Feature5': X5_unmon,\n",
        "    'Feature6': X6_unmon,\n",
        "    'Feature7': X7_unmon,\n",
        "    'Feature8': X8_unmon,\n",
        "    'Feature9': X9_unmon,\n",
        "    #'Feature11': X11_unmon, #중요도 검사후 주석 처리 함\n",
        "    'Feature12': X12_unmon,\n",
        "    'Feature14': X14_unmon,\n",
        "    #'Feature15': X15_unmon, #중요도 검사후 주석 처리 함\n",
        "    'Feature16': X16_unmon,\n",
        "    #'Feature17': X17_unmon  #중요도 검사후 주석 처리 함\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5USGlvPDvpI2",
        "outputId": "3e47cab4-c1a2-410d-e641-7c9e6a1b1180"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Feature1  Feature3  Feature5  Feature6  Feature7  Feature8  Feature9  \\\n",
              "0      0.007141   26060.8      1300  0.085151  0.914849  1.934185       121   \n",
              "1      0.019652   14796.8       438  0.154440  0.845560  1.540626        80   \n",
              "2      0.008187   24729.6      1240  0.086892  0.913108  1.973276       118   \n",
              "3      0.009246   27136.0      1324  0.084371  0.915629  2.832813       122   \n",
              "4      0.007573   24422.4      1291  0.081792  0.918208  2.179823       115   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "18995  0.004655   36812.8      8815  0.065614  0.934386  4.342246       619   \n",
              "18996  0.001567   41216.0      9404  0.055444  0.944556  2.758278       552   \n",
              "18997  0.001500   34252.8      9373  0.058179  0.941821  2.893279       579   \n",
              "18998  0.002006   37683.2      9236  0.069514  0.930486  3.313856       690   \n",
              "18999  0.001387   36505.6      9168  0.076272  0.923728  2.720712       757   \n",
              "\n",
              "       Feature12  Feature14  Feature16  \n",
              "0           2842       1421   1.018253  \n",
              "1           1036        518   1.328057  \n",
              "2           2716       1358   1.068847  \n",
              "3           2892       1446   1.556907  \n",
              "4           2812       1406   1.180701  \n",
              "...          ...        ...        ...  \n",
              "18995      18868       9434   3.029885  \n",
              "18996      19912       9956   2.665505  \n",
              "18997      19904       9952   2.613620  \n",
              "18998      19852       9926   2.998973  \n",
              "18999      19850       9925   2.191058  \n",
              "\n",
              "[19000 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-375bf49a-63b2-431b-b226-e4b2364a743c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature1</th>\n",
              "      <th>Feature3</th>\n",
              "      <th>Feature5</th>\n",
              "      <th>Feature6</th>\n",
              "      <th>Feature7</th>\n",
              "      <th>Feature8</th>\n",
              "      <th>Feature9</th>\n",
              "      <th>Feature12</th>\n",
              "      <th>Feature14</th>\n",
              "      <th>Feature16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.007141</td>\n",
              "      <td>26060.8</td>\n",
              "      <td>1300</td>\n",
              "      <td>0.085151</td>\n",
              "      <td>0.914849</td>\n",
              "      <td>1.934185</td>\n",
              "      <td>121</td>\n",
              "      <td>2842</td>\n",
              "      <td>1421</td>\n",
              "      <td>1.018253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.019652</td>\n",
              "      <td>14796.8</td>\n",
              "      <td>438</td>\n",
              "      <td>0.154440</td>\n",
              "      <td>0.845560</td>\n",
              "      <td>1.540626</td>\n",
              "      <td>80</td>\n",
              "      <td>1036</td>\n",
              "      <td>518</td>\n",
              "      <td>1.328057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.008187</td>\n",
              "      <td>24729.6</td>\n",
              "      <td>1240</td>\n",
              "      <td>0.086892</td>\n",
              "      <td>0.913108</td>\n",
              "      <td>1.973276</td>\n",
              "      <td>118</td>\n",
              "      <td>2716</td>\n",
              "      <td>1358</td>\n",
              "      <td>1.068847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.009246</td>\n",
              "      <td>27136.0</td>\n",
              "      <td>1324</td>\n",
              "      <td>0.084371</td>\n",
              "      <td>0.915629</td>\n",
              "      <td>2.832813</td>\n",
              "      <td>122</td>\n",
              "      <td>2892</td>\n",
              "      <td>1446</td>\n",
              "      <td>1.556907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.007573</td>\n",
              "      <td>24422.4</td>\n",
              "      <td>1291</td>\n",
              "      <td>0.081792</td>\n",
              "      <td>0.918208</td>\n",
              "      <td>2.179823</td>\n",
              "      <td>115</td>\n",
              "      <td>2812</td>\n",
              "      <td>1406</td>\n",
              "      <td>1.180701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18995</th>\n",
              "      <td>0.004655</td>\n",
              "      <td>36812.8</td>\n",
              "      <td>8815</td>\n",
              "      <td>0.065614</td>\n",
              "      <td>0.934386</td>\n",
              "      <td>4.342246</td>\n",
              "      <td>619</td>\n",
              "      <td>18868</td>\n",
              "      <td>9434</td>\n",
              "      <td>3.029885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18996</th>\n",
              "      <td>0.001567</td>\n",
              "      <td>41216.0</td>\n",
              "      <td>9404</td>\n",
              "      <td>0.055444</td>\n",
              "      <td>0.944556</td>\n",
              "      <td>2.758278</td>\n",
              "      <td>552</td>\n",
              "      <td>19912</td>\n",
              "      <td>9956</td>\n",
              "      <td>2.665505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18997</th>\n",
              "      <td>0.001500</td>\n",
              "      <td>34252.8</td>\n",
              "      <td>9373</td>\n",
              "      <td>0.058179</td>\n",
              "      <td>0.941821</td>\n",
              "      <td>2.893279</td>\n",
              "      <td>579</td>\n",
              "      <td>19904</td>\n",
              "      <td>9952</td>\n",
              "      <td>2.613620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18998</th>\n",
              "      <td>0.002006</td>\n",
              "      <td>37683.2</td>\n",
              "      <td>9236</td>\n",
              "      <td>0.069514</td>\n",
              "      <td>0.930486</td>\n",
              "      <td>3.313856</td>\n",
              "      <td>690</td>\n",
              "      <td>19852</td>\n",
              "      <td>9926</td>\n",
              "      <td>2.998973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18999</th>\n",
              "      <td>0.001387</td>\n",
              "      <td>36505.6</td>\n",
              "      <td>9168</td>\n",
              "      <td>0.076272</td>\n",
              "      <td>0.923728</td>\n",
              "      <td>2.720712</td>\n",
              "      <td>757</td>\n",
              "      <td>19850</td>\n",
              "      <td>9925</td>\n",
              "      <td>2.191058</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19000 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-375bf49a-63b2-431b-b226-e4b2364a743c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-375bf49a-63b2-431b-b226-e4b2364a743c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-375bf49a-63b2-431b-b226-e4b2364a743c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d2c33186-e8e4-414e-a59e-6f97a2cc4279\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2c33186-e8e4-414e-a59e-6f97a2cc4279')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d2c33186-e8e4-414e-a59e-6f97a2cc4279 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df_mon = pd.DataFrame(data_mon)\n",
        "df_mon"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_unmon = pd.DataFrame(data_unmon)\n",
        "df_unmon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "hGUjMUoR2Kiz",
        "outputId": "231210f0-4a88-44b8-c150-455d1fe71d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Feature1  Feature3  Feature5  Feature6  Feature7  Feature8  Feature9  \\\n",
              "0     0.043101     16384       101  0.223077  0.776923  1.050736        29   \n",
              "1     0.001197     51200      9189  0.074343  0.925657  1.940547       738   \n",
              "2     0.049749     16896       285  0.206128  0.793872  3.475381        74   \n",
              "3     0.000922     43520      9407  0.054383  0.945617  1.313723       541   \n",
              "4     0.021376     35840      2215  0.116826  0.883174  8.507451       293   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "9995  0.006988     35328      4180  0.089919  0.910081  5.127064       413   \n",
              "9996  0.007559     44544      4663  0.087476  0.912524  4.348233       447   \n",
              "9997  0.097028     20992       302  0.163435  0.836565  7.707609        59   \n",
              "9998  0.023307     21504       413  0.188605  0.811395  2.842843        96   \n",
              "9999  0.000963     46080      9668  0.032232  0.967768  1.295610       322   \n",
              "\n",
              "      Feature12  Feature14  Feature16  \n",
              "0           260        130   1.240463  \n",
              "1         19854       9927   1.572821  \n",
              "2           718        359   2.939175  \n",
              "3         19896       9948   1.016587  \n",
              "4          5016       2508   5.034849  \n",
              "...         ...        ...        ...  \n",
              "9995       9186       4593   5.704984  \n",
              "9996      10220       5110   3.668209  \n",
              "9997        722        361   0.868159  \n",
              "9998       1018        509   2.130534  \n",
              "9999      19980       9990   0.997824  \n",
              "\n",
              "[10000 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c44c2e53-9130-428d-95cb-98866a06258e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature1</th>\n",
              "      <th>Feature3</th>\n",
              "      <th>Feature5</th>\n",
              "      <th>Feature6</th>\n",
              "      <th>Feature7</th>\n",
              "      <th>Feature8</th>\n",
              "      <th>Feature9</th>\n",
              "      <th>Feature12</th>\n",
              "      <th>Feature14</th>\n",
              "      <th>Feature16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.043101</td>\n",
              "      <td>16384</td>\n",
              "      <td>101</td>\n",
              "      <td>0.223077</td>\n",
              "      <td>0.776923</td>\n",
              "      <td>1.050736</td>\n",
              "      <td>29</td>\n",
              "      <td>260</td>\n",
              "      <td>130</td>\n",
              "      <td>1.240463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001197</td>\n",
              "      <td>51200</td>\n",
              "      <td>9189</td>\n",
              "      <td>0.074343</td>\n",
              "      <td>0.925657</td>\n",
              "      <td>1.940547</td>\n",
              "      <td>738</td>\n",
              "      <td>19854</td>\n",
              "      <td>9927</td>\n",
              "      <td>1.572821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.049749</td>\n",
              "      <td>16896</td>\n",
              "      <td>285</td>\n",
              "      <td>0.206128</td>\n",
              "      <td>0.793872</td>\n",
              "      <td>3.475381</td>\n",
              "      <td>74</td>\n",
              "      <td>718</td>\n",
              "      <td>359</td>\n",
              "      <td>2.939175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000922</td>\n",
              "      <td>43520</td>\n",
              "      <td>9407</td>\n",
              "      <td>0.054383</td>\n",
              "      <td>0.945617</td>\n",
              "      <td>1.313723</td>\n",
              "      <td>541</td>\n",
              "      <td>19896</td>\n",
              "      <td>9948</td>\n",
              "      <td>1.016587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.021376</td>\n",
              "      <td>35840</td>\n",
              "      <td>2215</td>\n",
              "      <td>0.116826</td>\n",
              "      <td>0.883174</td>\n",
              "      <td>8.507451</td>\n",
              "      <td>293</td>\n",
              "      <td>5016</td>\n",
              "      <td>2508</td>\n",
              "      <td>5.034849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0.006988</td>\n",
              "      <td>35328</td>\n",
              "      <td>4180</td>\n",
              "      <td>0.089919</td>\n",
              "      <td>0.910081</td>\n",
              "      <td>5.127064</td>\n",
              "      <td>413</td>\n",
              "      <td>9186</td>\n",
              "      <td>4593</td>\n",
              "      <td>5.704984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0.007559</td>\n",
              "      <td>44544</td>\n",
              "      <td>4663</td>\n",
              "      <td>0.087476</td>\n",
              "      <td>0.912524</td>\n",
              "      <td>4.348233</td>\n",
              "      <td>447</td>\n",
              "      <td>10220</td>\n",
              "      <td>5110</td>\n",
              "      <td>3.668209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0.097028</td>\n",
              "      <td>20992</td>\n",
              "      <td>302</td>\n",
              "      <td>0.163435</td>\n",
              "      <td>0.836565</td>\n",
              "      <td>7.707609</td>\n",
              "      <td>59</td>\n",
              "      <td>722</td>\n",
              "      <td>361</td>\n",
              "      <td>0.868159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>0.023307</td>\n",
              "      <td>21504</td>\n",
              "      <td>413</td>\n",
              "      <td>0.188605</td>\n",
              "      <td>0.811395</td>\n",
              "      <td>2.842843</td>\n",
              "      <td>96</td>\n",
              "      <td>1018</td>\n",
              "      <td>509</td>\n",
              "      <td>2.130534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0.000963</td>\n",
              "      <td>46080</td>\n",
              "      <td>9668</td>\n",
              "      <td>0.032232</td>\n",
              "      <td>0.967768</td>\n",
              "      <td>1.295610</td>\n",
              "      <td>322</td>\n",
              "      <td>19980</td>\n",
              "      <td>9990</td>\n",
              "      <td>0.997824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c44c2e53-9130-428d-95cb-98866a06258e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c44c2e53-9130-428d-95cb-98866a06258e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c44c2e53-9130-428d-95cb-98866a06258e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8ca49290-1c3b-4680-859b-b1d237696508\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8ca49290-1c3b-4680-859b-b1d237696508')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8ca49290-1c3b-4680-859b-b1d237696508 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "HGRLWOzFvxEX",
        "outputId": "53098098-848e-4009-d3e0-1c51532edf08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0\n",
              "0       0\n",
              "1       0\n",
              "2       0\n",
              "3       0\n",
              "4       0\n",
              "...    ..\n",
              "18995  94\n",
              "18996  94\n",
              "18997  94\n",
              "18998  94\n",
              "18999  94\n",
              "\n",
              "[19000 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cad8778-c8eb-4192-a6d2-0eb3298d3d32\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18995</th>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18996</th>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18997</th>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18998</th>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18999</th>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19000 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cad8778-c8eb-4192-a6d2-0eb3298d3d32')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3cad8778-c8eb-4192-a6d2-0eb3298d3d32 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3cad8778-c8eb-4192-a6d2-0eb3298d3d32');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7382b9d9-6537-4393-aa12-696313fceda6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7382b9d9-6537-4393-aa12-696313fceda6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7382b9d9-6537-4393-aa12-696313fceda6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df_y_mon = pd.DataFrame(y_mon)\n",
        "df_y_mon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHK2D4m7uNi_"
      },
      "source": [
        "##unmon 데이터프레임으로 합치기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "KeYblwV12AlZ",
        "outputId": "a8dee510-be02-4da9-c672-4cf6678515ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0\n",
              "0    -1\n",
              "1    -1\n",
              "2    -1\n",
              "3    -1\n",
              "4    -1\n",
              "...  ..\n",
              "9995 -1\n",
              "9996 -1\n",
              "9997 -1\n",
              "9998 -1\n",
              "9999 -1\n",
              "\n",
              "[10000 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6b46e61-6ad9-4285-ac33-ea8781e198e0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6b46e61-6ad9-4285-ac33-ea8781e198e0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b6b46e61-6ad9-4285-ac33-ea8781e198e0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b6b46e61-6ad9-4285-ac33-ea8781e198e0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a3f9cc42-1e3c-43b5-adc8-01d2493df572\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3f9cc42-1e3c-43b5-adc8-01d2493df572')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a3f9cc42-1e3c-43b5-adc8-01d2493df572 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "y_unmon = {'0': [-1] * 10000}\n",
        "df_y_unmon = pd.DataFrame(y_unmon)\n",
        "df_y_unmon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLZTb81rwuQn"
      },
      "source": [
        "##2. unmon + mon 합쳐서 total 데이터셋 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xDe5RwIwt-p"
      },
      "outputs": [],
      "source": [
        "data_x_total = pd.DataFrame({\n",
        "    'Feature1': [X1_unmon, X1_mon],\n",
        "    'Feature3': [X3_unmon, X3_mon],  # 추가할 Feature3\n",
        "    'Feature5': [X5_unmon, X5_mon],\n",
        "    'Feature6': [X6_unmon, X6_mon],\n",
        "    'Feature7': [X7_unmon, X7_mon],\n",
        "    'Feature8': [X8_unmon, X8_mon],\n",
        "    'Feature9': [X9_unmon, X9_mon],\n",
        "    #'Feature11': [X11_unmon, X11_mon], #마찬가지로 중요도 검사 후 주석 처리함.\n",
        "    'Feature12': [X12_unmon, X12_mon],\n",
        "    'Feature14': [X14_unmon, X14_mon],\n",
        "    #'Feature15': [X15_unmon, X15_mon], #마찬가지로 중요도 검사 후 주석 처리함.\n",
        "    'Feature16': [X16_unmon, X16_mon],\n",
        "    #'Feature17': [X17_unmon, X17_mon] #마찬가지로 중요도 검사 후 주석 처리함.\n",
        "})\n",
        "\n",
        "data_total = pd.concat([df_unmon, df_mon], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "f8fnOiNhyH4q",
        "outputId": "c431bcc7-7c0a-4253-d87c-0680cff5b80d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Feature1  Feature3  Feature5  Feature6  Feature7  Feature8  Feature9  \\\n",
              "0      0.043101   16384.0       101  0.223077  0.776923  1.050736        29   \n",
              "1      0.001197   51200.0      9189  0.074343  0.925657  1.940547       738   \n",
              "2      0.049749   16896.0       285  0.206128  0.793872  3.475381        74   \n",
              "3      0.000922   43520.0      9407  0.054383  0.945617  1.313723       541   \n",
              "4      0.021376   35840.0      2215  0.116826  0.883174  8.507451       293   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "28995  0.004655   36812.8      8815  0.065614  0.934386  4.342246       619   \n",
              "28996  0.001567   41216.0      9404  0.055444  0.944556  2.758278       552   \n",
              "28997  0.001500   34252.8      9373  0.058179  0.941821  2.893279       579   \n",
              "28998  0.002006   37683.2      9236  0.069514  0.930486  3.313856       690   \n",
              "28999  0.001387   36505.6      9168  0.076272  0.923728  2.720712       757   \n",
              "\n",
              "       Feature12  Feature14  Feature16  \n",
              "0            260        130   1.240463  \n",
              "1          19854       9927   1.572821  \n",
              "2            718        359   2.939175  \n",
              "3          19896       9948   1.016587  \n",
              "4           5016       2508   5.034849  \n",
              "...          ...        ...        ...  \n",
              "28995      18868       9434   3.029885  \n",
              "28996      19912       9956   2.665505  \n",
              "28997      19904       9952   2.613620  \n",
              "28998      19852       9926   2.998973  \n",
              "28999      19850       9925   2.191058  \n",
              "\n",
              "[29000 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ffb93f3b-6a22-4808-bcf5-1f5f9804efb7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature1</th>\n",
              "      <th>Feature3</th>\n",
              "      <th>Feature5</th>\n",
              "      <th>Feature6</th>\n",
              "      <th>Feature7</th>\n",
              "      <th>Feature8</th>\n",
              "      <th>Feature9</th>\n",
              "      <th>Feature12</th>\n",
              "      <th>Feature14</th>\n",
              "      <th>Feature16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.043101</td>\n",
              "      <td>16384.0</td>\n",
              "      <td>101</td>\n",
              "      <td>0.223077</td>\n",
              "      <td>0.776923</td>\n",
              "      <td>1.050736</td>\n",
              "      <td>29</td>\n",
              "      <td>260</td>\n",
              "      <td>130</td>\n",
              "      <td>1.240463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001197</td>\n",
              "      <td>51200.0</td>\n",
              "      <td>9189</td>\n",
              "      <td>0.074343</td>\n",
              "      <td>0.925657</td>\n",
              "      <td>1.940547</td>\n",
              "      <td>738</td>\n",
              "      <td>19854</td>\n",
              "      <td>9927</td>\n",
              "      <td>1.572821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.049749</td>\n",
              "      <td>16896.0</td>\n",
              "      <td>285</td>\n",
              "      <td>0.206128</td>\n",
              "      <td>0.793872</td>\n",
              "      <td>3.475381</td>\n",
              "      <td>74</td>\n",
              "      <td>718</td>\n",
              "      <td>359</td>\n",
              "      <td>2.939175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000922</td>\n",
              "      <td>43520.0</td>\n",
              "      <td>9407</td>\n",
              "      <td>0.054383</td>\n",
              "      <td>0.945617</td>\n",
              "      <td>1.313723</td>\n",
              "      <td>541</td>\n",
              "      <td>19896</td>\n",
              "      <td>9948</td>\n",
              "      <td>1.016587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.021376</td>\n",
              "      <td>35840.0</td>\n",
              "      <td>2215</td>\n",
              "      <td>0.116826</td>\n",
              "      <td>0.883174</td>\n",
              "      <td>8.507451</td>\n",
              "      <td>293</td>\n",
              "      <td>5016</td>\n",
              "      <td>2508</td>\n",
              "      <td>5.034849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28995</th>\n",
              "      <td>0.004655</td>\n",
              "      <td>36812.8</td>\n",
              "      <td>8815</td>\n",
              "      <td>0.065614</td>\n",
              "      <td>0.934386</td>\n",
              "      <td>4.342246</td>\n",
              "      <td>619</td>\n",
              "      <td>18868</td>\n",
              "      <td>9434</td>\n",
              "      <td>3.029885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28996</th>\n",
              "      <td>0.001567</td>\n",
              "      <td>41216.0</td>\n",
              "      <td>9404</td>\n",
              "      <td>0.055444</td>\n",
              "      <td>0.944556</td>\n",
              "      <td>2.758278</td>\n",
              "      <td>552</td>\n",
              "      <td>19912</td>\n",
              "      <td>9956</td>\n",
              "      <td>2.665505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28997</th>\n",
              "      <td>0.001500</td>\n",
              "      <td>34252.8</td>\n",
              "      <td>9373</td>\n",
              "      <td>0.058179</td>\n",
              "      <td>0.941821</td>\n",
              "      <td>2.893279</td>\n",
              "      <td>579</td>\n",
              "      <td>19904</td>\n",
              "      <td>9952</td>\n",
              "      <td>2.613620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28998</th>\n",
              "      <td>0.002006</td>\n",
              "      <td>37683.2</td>\n",
              "      <td>9236</td>\n",
              "      <td>0.069514</td>\n",
              "      <td>0.930486</td>\n",
              "      <td>3.313856</td>\n",
              "      <td>690</td>\n",
              "      <td>19852</td>\n",
              "      <td>9926</td>\n",
              "      <td>2.998973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28999</th>\n",
              "      <td>0.001387</td>\n",
              "      <td>36505.6</td>\n",
              "      <td>9168</td>\n",
              "      <td>0.076272</td>\n",
              "      <td>0.923728</td>\n",
              "      <td>2.720712</td>\n",
              "      <td>757</td>\n",
              "      <td>19850</td>\n",
              "      <td>9925</td>\n",
              "      <td>2.191058</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29000 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffb93f3b-6a22-4808-bcf5-1f5f9804efb7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ffb93f3b-6a22-4808-bcf5-1f5f9804efb7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ffb93f3b-6a22-4808-bcf5-1f5f9804efb7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bad7ec06-721c-424d-b3bd-7e8eb8cd6e27\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bad7ec06-721c-424d-b3bd-7e8eb8cd6e27')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bad7ec06-721c-424d-b3bd-7e8eb8cd6e27 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Gd6DZZNxWQA"
      },
      "outputs": [],
      "source": [
        "data_y_total = pd.concat([df_y_unmon.iloc[:,0], df_y_mon.iloc[:,0]], axis=0, ignore_index=True)\n",
        "data_y_total = data_y_total.to_frame()  # Series를 DataFrame으로 변환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lMjKtE0iyOxY",
        "outputId": "f59858ab-fdb9-404a-bf79-a15672b209b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0\n",
              "0      -1\n",
              "1      -1\n",
              "2      -1\n",
              "3      -1\n",
              "4      -1\n",
              "...    ..\n",
              "28995  94\n",
              "28996  94\n",
              "28997  94\n",
              "28998  94\n",
              "28999  94\n",
              "\n",
              "[29000 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97ba95ee-b739-48d2-b6a3-249606fd2cda\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28995</th>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28996</th>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28997</th>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28998</th>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28999</th>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29000 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97ba95ee-b739-48d2-b6a3-249606fd2cda')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-97ba95ee-b739-48d2-b6a3-249606fd2cda button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-97ba95ee-b739-48d2-b6a3-249606fd2cda');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5d4d482c-32fd-41a7-8877-341015ea02f9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5d4d482c-32fd-41a7-8877-341015ea02f9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5d4d482c-32fd-41a7-8877-341015ea02f9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data_y_total"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#공통 data split 용."
      ],
      "metadata": {
        "id": "WqiNWdnMczLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_total, data_y_total, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "U1yV6d08cweI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87IiNxwW2tC5"
      },
      "source": [
        "## 모델 Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooFscDqNSgvj"
      },
      "source": [
        "#1.logistic regression\n",
        " (1.데이터샘플링,2.차원축소, 3.미니배치)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "It6iEcmzTr-I"
      },
      "source": [
        "#1) Logistic Regression Accuracy (Sampled Data): 0.3431034482758621\n",
        "\n",
        "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
        "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
        "Please also refer to the documentation for alternative solver options:\n",
        "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
        "  n_iter_i = _check_optimize_result(\n",
        "\n",
        "    해당 오류는 결과값이 선형으로 수렴하지 않는다는 경고이다. 즉, 우리의 데이터는 복잡한 비선형 구조를 띄고 있다고 이해할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OuAmUyJSv7H",
        "outputId": "d5f13cc2-9580-43f9-eee7-7eb8f4c96e5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy (Sampled Data): 0.3431034482758621\n",
            "Logistic Regression Classification Report (Sampled Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.36      0.99      0.52       194\n",
            "           0       1.00      0.00      0.00         4\n",
            "           1       1.00      0.00      0.00         4\n",
            "           2       1.00      0.00      0.00         4\n",
            "           3       1.00      0.00      0.00         5\n",
            "           4       1.00      0.00      0.00         5\n",
            "           5       1.00      0.00      0.00         6\n",
            "           6       1.00      0.00      0.00         5\n",
            "           7       1.00      0.00      0.00         3\n",
            "           8       1.00      0.00      0.00         8\n",
            "           9       1.00      0.00      0.00         9\n",
            "          10       1.00      0.00      0.00         7\n",
            "          11       1.00      0.00      0.00         5\n",
            "          12       1.00      0.00      0.00         2\n",
            "          13       1.00      0.00      0.00         1\n",
            "          14       1.00      0.00      0.00         1\n",
            "          15       1.00      0.00      0.00         6\n",
            "          16       1.00      0.00      0.00         3\n",
            "          17       1.00      0.00      0.00         5\n",
            "          18       1.00      0.00      0.00         5\n",
            "          19       1.00      0.00      0.00         6\n",
            "          20       1.00      0.00      0.00         2\n",
            "          21       1.00      0.00      0.00         3\n",
            "          22       1.00      0.00      0.00         3\n",
            "          23       1.00      0.00      0.00         1\n",
            "          24       1.00      0.00      0.00         3\n",
            "          25       1.00      0.00      0.00         2\n",
            "          26       1.00      0.00      0.00         5\n",
            "          27       1.00      0.00      0.00         2\n",
            "          28       1.00      0.00      0.00         9\n",
            "          29       1.00      0.00      0.00         4\n",
            "          30       0.00      0.00      0.00         3\n",
            "          31       1.00      0.00      0.00         3\n",
            "          32       1.00      0.00      0.00         4\n",
            "          33       1.00      0.00      0.00         5\n",
            "          34       0.11      0.33      0.17         3\n",
            "          35       1.00      0.00      0.00         3\n",
            "          36       1.00      0.00      0.00         4\n",
            "          37       1.00      0.00      0.00         4\n",
            "          38       1.00      0.00      0.00         4\n",
            "          39       1.00      0.00      0.00         4\n",
            "          40       1.00      0.00      0.00         6\n",
            "          41       1.00      0.00      0.00         1\n",
            "          42       0.00      1.00      0.00         0\n",
            "          43       1.00      0.00      0.00         8\n",
            "          44       1.00      0.00      0.00         3\n",
            "          45       1.00      0.00      0.00         3\n",
            "          46       1.00      0.00      0.00         3\n",
            "          47       1.00      0.00      0.00         3\n",
            "          48       1.00      0.00      0.00         4\n",
            "          49       1.00      0.00      0.00         5\n",
            "          50       1.00      0.00      0.00         2\n",
            "          51       1.00      0.00      0.00         3\n",
            "          52       1.00      0.00      0.00         5\n",
            "          53       1.00      0.00      0.00         1\n",
            "          54       1.00      0.00      0.00         3\n",
            "          55       1.00      0.00      0.00         5\n",
            "          56       1.00      0.00      0.00         3\n",
            "          57       1.00      0.00      0.00         3\n",
            "          58       1.00      0.00      0.00         4\n",
            "          59       1.00      0.00      0.00         8\n",
            "          60       1.00      0.00      0.00         3\n",
            "          61       1.00      0.00      0.00         2\n",
            "          62       0.00      0.00      0.00         6\n",
            "          63       1.00      0.00      0.00         2\n",
            "          64       0.25      0.25      0.25         4\n",
            "          65       1.00      0.00      0.00         3\n",
            "          66       1.00      0.00      0.00         5\n",
            "          67       1.00      0.00      0.00         6\n",
            "          68       1.00      0.00      0.00         4\n",
            "          69       1.00      0.00      0.00         5\n",
            "          70       1.00      0.00      0.00         1\n",
            "          71       1.00      0.00      0.00         5\n",
            "          72       1.00      0.00      0.00         9\n",
            "          73       0.30      0.75      0.43         4\n",
            "          74       0.20      0.25      0.22         4\n",
            "          75       1.00      0.00      0.00         5\n",
            "          76       1.00      0.00      0.00         8\n",
            "          77       1.00      0.00      0.00         5\n",
            "          78       1.00      0.00      0.00         6\n",
            "          79       1.00      0.00      0.00         4\n",
            "          80       1.00      0.00      0.00         3\n",
            "          81       1.00      0.00      0.00         4\n",
            "          82       1.00      0.00      0.00         2\n",
            "          83       1.00      0.00      0.00         5\n",
            "          84       1.00      0.00      0.00         4\n",
            "          85       1.00      0.00      0.00         8\n",
            "          86       1.00      0.00      0.00         3\n",
            "          87       1.00      0.00      0.00         3\n",
            "          88       1.00      0.00      0.00         2\n",
            "          89       0.25      0.33      0.29         3\n",
            "          90       1.00      0.00      0.00         4\n",
            "          91       1.00      0.00      0.00         4\n",
            "          92       1.00      0.00      0.00         2\n",
            "          93       1.00      0.00      0.00         3\n",
            "          94       1.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.34       580\n",
            "   macro avg       0.92      0.04      0.02       580\n",
            "weighted avg       0.75      0.34      0.18       580\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "#1. 데이터 샘플링:\n",
        "#무작위로 데이터를 샘플링하여 작은 규모의 훈련 데이터셋을 만들고 Logistic Regression 모델을 훈련하는 코드입니다.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 데이터 샘플링\n",
        "sampled_data = data_total.sample(frac=0.1, random_state=42)\n",
        "sampled_labels = data_y_total.loc[sampled_data.index]\n",
        "\n",
        "# 데이터 분할\n",
        "X_train_sampled, X_test_sampled, y_train_sampled, y_test_sampled = train_test_split(\n",
        "    sampled_data, sampled_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# Logistic Regression 모델 훈련\n",
        "clf_LR_sampled = LogisticRegression(max_iter=5000)\n",
        "clf_LR_sampled.fit(X_train_sampled, y_train_sampled.values.ravel())\n",
        "\n",
        "# 모델 평가\n",
        "y_pred_sampled = clf_LR_sampled.predict(X_test_sampled)\n",
        "accuracy_sampled = accuracy_score(y_test_sampled, y_pred_sampled)\n",
        "classification_report_sampled = classification_report(y_test_sampled, y_pred_sampled, zero_division=1)\n",
        "\n",
        "print(\"Logistic Regression Accuracy (Sampled Data):\", accuracy_sampled)\n",
        "print(\"Logistic Regression Classification Report (Sampled Data):\")\n",
        "print(classification_report_sampled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RivGvwydg19z"
      },
      "source": [
        "결과값을 해석하자면 -1로 할당된 class가 너무 많다. 즉, 클래스가 불균형한 것이다. 이런 경우 튜닝이 필요하다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiKexh1Ig90S",
        "outputId": "0884bc76-a862-4e53-d6d3-4f557e11ea4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.056896551724137934\n",
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.00      0.00       194\n",
            "           0       0.00      0.00      0.00         4\n",
            "           1       0.00      0.00      0.00         4\n",
            "           2       1.00      0.00      0.00         4\n",
            "           3       1.00      0.00      0.00         5\n",
            "           4       1.00      0.00      0.00         5\n",
            "           5       0.09      0.17      0.12         6\n",
            "           6       0.00      0.00      0.00         5\n",
            "           7       0.04      0.33      0.08         3\n",
            "           8       1.00      0.00      0.00         8\n",
            "           9       1.00      0.00      0.00         9\n",
            "          10       1.00      0.00      0.00         7\n",
            "          11       0.50      0.20      0.29         5\n",
            "          12       0.00      0.00      0.00         2\n",
            "          13       1.00      0.00      0.00         1\n",
            "          14       1.00      0.00      0.00         1\n",
            "          15       0.08      0.17      0.11         6\n",
            "          16       1.00      0.00      0.00         3\n",
            "          17       1.00      0.00      0.00         5\n",
            "          18       1.00      0.00      0.00         5\n",
            "          19       0.06      0.17      0.08         6\n",
            "          20       1.00      0.00      0.00         2\n",
            "          21       0.00      0.00      0.00         3\n",
            "          22       0.00      0.00      0.00         3\n",
            "          23       0.00      0.00      0.00         1\n",
            "          24       0.00      0.00      0.00         3\n",
            "          25       1.00      0.00      0.00         2\n",
            "          26       1.00      0.00      0.00         5\n",
            "          27       0.00      0.00      0.00         2\n",
            "          28       1.00      0.00      0.00         9\n",
            "          29       0.20      0.50      0.29         4\n",
            "          30       0.00      0.00      0.00         3\n",
            "          31       0.00      0.00      0.00         3\n",
            "          32       1.00      0.00      0.00         4\n",
            "          33       1.00      0.00      0.00         5\n",
            "          34       0.08      0.33      0.13         3\n",
            "          35       1.00      0.00      0.00         3\n",
            "          36       0.00      0.00      0.00         4\n",
            "          37       1.00      0.00      0.00         4\n",
            "          38       1.00      0.00      0.00         4\n",
            "          39       1.00      0.00      0.00         4\n",
            "          40       0.00      0.00      0.00         6\n",
            "          41       0.00      0.00      0.00         1\n",
            "          42       0.00      1.00      0.00         0\n",
            "          43       1.00      0.00      0.00         8\n",
            "          44       0.17      0.33      0.22         3\n",
            "          45       0.00      0.00      0.00         3\n",
            "          46       1.00      0.00      0.00         3\n",
            "          47       0.05      0.33      0.08         3\n",
            "          48       0.06      0.50      0.11         4\n",
            "          49       1.00      0.00      0.00         5\n",
            "          50       0.00      0.00      0.00         2\n",
            "          51       0.00      0.00      0.00         3\n",
            "          52       1.00      0.00      0.00         5\n",
            "          53       1.00      0.00      0.00         1\n",
            "          54       0.00      0.00      0.00         3\n",
            "          55       0.00      0.00      0.00         5\n",
            "          56       1.00      0.00      0.00         3\n",
            "          57       1.00      0.00      0.00         3\n",
            "          58       0.00      0.00      0.00         4\n",
            "          59       0.00      0.00      0.00         8\n",
            "          60       0.00      0.00      0.00         3\n",
            "          61       1.00      0.00      0.00         2\n",
            "          62       0.00      0.00      0.00         6\n",
            "          63       0.00      0.00      0.00         2\n",
            "          64       0.33      0.25      0.29         4\n",
            "          65       0.06      0.67      0.11         3\n",
            "          66       0.10      0.20      0.13         5\n",
            "          67       0.20      0.33      0.25         6\n",
            "          68       1.00      0.00      0.00         4\n",
            "          69       0.09      0.20      0.13         5\n",
            "          70       0.03      1.00      0.05         1\n",
            "          71       1.00      0.00      0.00         5\n",
            "          72       1.00      0.00      0.00         9\n",
            "          73       0.31      1.00      0.47         4\n",
            "          74       0.12      0.25      0.17         4\n",
            "          75       0.14      0.80      0.24         5\n",
            "          76       1.00      0.00      0.00         8\n",
            "          77       1.00      0.00      0.00         5\n",
            "          78       1.00      0.00      0.00         6\n",
            "          79       0.08      0.25      0.12         4\n",
            "          80       0.04      0.33      0.07         3\n",
            "          81       1.00      0.00      0.00         4\n",
            "          82       1.00      0.00      0.00         2\n",
            "          83       1.00      0.00      0.00         5\n",
            "          84       0.50      0.25      0.33         4\n",
            "          85       1.00      0.00      0.00         8\n",
            "          86       1.00      0.00      0.00         3\n",
            "          87       1.00      0.00      0.00         3\n",
            "          88       0.00      0.00      0.00         2\n",
            "          89       0.20      0.33      0.25         3\n",
            "          90       1.00      0.00      0.00         4\n",
            "          91       0.00      0.00      0.00         4\n",
            "          92       0.00      0.00      0.00         2\n",
            "          93       0.00      0.00      0.00         3\n",
            "          94       1.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.06       580\n",
            "   macro avg       0.50      0.10      0.04       580\n",
            "weighted avg       0.70      0.06      0.03       580\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "#1. data sampling 튜닝하기\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 샘플링 (Random Oversampling)\n",
        "oversample = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
        "X_over, y_over = oversample.fit_resample(X_train_sampled, y_train_sampled)\n",
        "\n",
        "# 클래스 -1에 대한 가중치는 1로 설정\n",
        "class_weights = {-1: 1}\n",
        "\n",
        "# 나머지 클래스에 대한 가중치 설정\n",
        "for i in range(94):\n",
        "    if i != -1:\n",
        "        class_weights[i] = 5 # 클래스 -1의 샘플 수에 비례하여 가중치 설정 (10,000 / 2000)\n",
        "\n",
        "\n",
        "# Logistic Regression 모델 생성 시 class_weight 매개변수를 지정하여 가중치 부여\n",
        "clf = LogisticRegression(class_weight=class_weights, max_iter=5000)\n",
        "\n",
        "# 모델 학습\n",
        "clf.fit(X_over, y_over)\n",
        "\n",
        "# 모델 평가\n",
        "y_pred = clf.predict(X_test_sampled)\n",
        "accuracy = accuracy_score(y_test_sampled, y_pred)\n",
        "classification_report_output = classification_report(y_test_sampled, y_pred, zero_division=1)\n",
        "\n",
        "print(\"Logistic Regression Accuracy:\", accuracy)\n",
        "print(\"Logistic Regression Classification Report:\")\n",
        "print(classification_report_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnxEDa1jYBQk"
      },
      "source": [
        "#2)Logistic Regression Accuracy (PCA): 0.34413793103448276\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vez7RFUVUBj",
        "outputId": "96ec504b-c7d5-4367-fb7c-e040f7c995cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy (PCA): 0.32\n",
            "Logistic Regression Classification Report (PCA):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.56      0.77      0.65      2058\n",
            "           0       0.00      0.00      0.00        41\n",
            "           1       0.00      0.00      0.00        35\n",
            "           2       0.00      0.00      0.00        43\n",
            "           3       0.00      0.00      0.00        41\n",
            "           4       0.00      0.00      0.00        44\n",
            "           5       0.00      0.00      0.00        40\n",
            "           6       0.00      0.00      0.00        31\n",
            "           7       0.00      0.00      0.00        42\n",
            "           8       0.00      0.00      0.00        43\n",
            "           9       0.00      0.00      0.00        37\n",
            "          10       0.00      0.00      0.00        43\n",
            "          11       0.06      0.30      0.09        30\n",
            "          12       0.00      0.00      0.00        42\n",
            "          13       0.00      0.00      0.00        37\n",
            "          14       0.00      0.00      0.00        35\n",
            "          15       0.00      0.00      0.00        33\n",
            "          16       0.01      0.03      0.01        39\n",
            "          17       0.00      0.00      0.00        33\n",
            "          18       0.00      0.00      0.00        46\n",
            "          19       0.00      0.00      0.00        43\n",
            "          20       0.00      0.00      0.00        51\n",
            "          21       0.00      0.00      0.00        48\n",
            "          22       0.00      0.00      0.00        42\n",
            "          23       0.07      0.14      0.10        29\n",
            "          24       0.12      0.11      0.11        56\n",
            "          25       0.00      0.00      0.00        45\n",
            "          26       0.03      0.02      0.02        43\n",
            "          27       0.00      0.00      0.00        34\n",
            "          28       0.01      0.05      0.02        37\n",
            "          29       0.00      0.00      0.00        39\n",
            "          30       0.11      0.44      0.18        41\n",
            "          31       0.00      0.00      0.00        56\n",
            "          32       0.00      0.00      0.00        40\n",
            "          33       0.00      0.00      0.00        43\n",
            "          34       0.09      0.45      0.15        31\n",
            "          35       0.00      0.00      0.00        42\n",
            "          36       0.00      0.00      0.00        44\n",
            "          37       0.00      0.00      0.00        35\n",
            "          38       0.00      0.00      0.00        34\n",
            "          39       0.00      0.00      0.00        43\n",
            "          40       0.00      0.00      0.00        39\n",
            "          41       0.04      0.03      0.03        39\n",
            "          42       0.00      0.00      0.00        40\n",
            "          43       0.11      0.09      0.10        44\n",
            "          44       0.05      0.05      0.05        37\n",
            "          45       0.00      0.00      0.00        44\n",
            "          46       0.00      0.00      0.00        41\n",
            "          47       0.00      0.00      0.00        30\n",
            "          48       0.00      0.00      0.00        46\n",
            "          49       0.00      0.00      0.00        28\n",
            "          50       0.67      0.30      0.41        40\n",
            "          51       0.00      0.00      0.00        32\n",
            "          52       0.00      0.00      0.00        46\n",
            "          53       0.00      0.00      0.00        51\n",
            "          54       0.00      0.00      0.00        35\n",
            "          55       0.00      0.00      0.00        42\n",
            "          56       0.00      0.00      0.00        42\n",
            "          57       0.00      0.00      0.00        41\n",
            "          58       0.00      0.00      0.00        39\n",
            "          59       0.00      0.00      0.00        44\n",
            "          60       0.00      0.00      0.00        48\n",
            "          61       0.00      0.00      0.00        34\n",
            "          62       0.12      0.17      0.14        36\n",
            "          63       0.00      0.00      0.00        41\n",
            "          64       0.26      0.25      0.26        44\n",
            "          65       0.00      0.00      0.00        38\n",
            "          66       0.15      0.35      0.21        37\n",
            "          67       0.08      0.04      0.05        27\n",
            "          68       0.04      0.03      0.03        35\n",
            "          69       0.60      0.07      0.12        45\n",
            "          70       0.13      0.90      0.23        40\n",
            "          71       0.00      0.00      0.00        39\n",
            "          72       0.00      0.00      0.00        29\n",
            "          73       0.09      0.93      0.16        30\n",
            "          74       0.08      0.58      0.14        33\n",
            "          75       0.09      0.98      0.16        41\n",
            "          76       0.00      0.00      0.00        41\n",
            "          77       0.00      0.00      0.00        35\n",
            "          78       0.00      0.00      0.00        38\n",
            "          79       0.04      0.08      0.05        39\n",
            "          80       0.12      0.31      0.18        42\n",
            "          81       0.00      0.00      0.00        41\n",
            "          82       0.00      0.00      0.00        40\n",
            "          83       0.00      0.00      0.00        40\n",
            "          84       0.00      0.00      0.00        37\n",
            "          85       0.00      0.00      0.00        40\n",
            "          86       0.08      0.04      0.06        46\n",
            "          87       0.00      0.00      0.00        37\n",
            "          88       0.00      0.00      0.00        40\n",
            "          89       0.14      0.20      0.16        35\n",
            "          90       0.07      0.09      0.08        35\n",
            "          91       0.17      0.15      0.16        41\n",
            "          92       0.00      0.00      0.00        30\n",
            "          93       0.00      0.00      0.00        42\n",
            "          94       0.17      0.03      0.05        35\n",
            "\n",
            "    accuracy                           0.32      5800\n",
            "   macro avg       0.05      0.08      0.04      5800\n",
            "weighted avg       0.23      0.32      0.25      5800\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터를 훈련 및 테스트 세트로 나누기\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_total, data_y_total, test_size=0.2, random_state=1)\n",
        "\n",
        "# 차원 축소 모델 생성 및 훈련 데이터에 적용\n",
        "pca = PCA(n_components=7)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Logistic Regression 모델 훈련\n",
        "clf_LR_pca = LogisticRegression(max_iter=5000)\n",
        "clf_LR_pca.fit(X_train_pca, y_train.values.ravel())\n",
        "\n",
        "# 모델 평가\n",
        "y_pred_pca = clf_LR_pca.predict(X_test_pca)\n",
        "accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
        "classification_report_pca = classification_report(y_test, y_pred_pca)\n",
        "\n",
        "print(\"Logistic Regression Accuracy (PCA):\", accuracy_pca)\n",
        "print(\"Logistic Regression Classification Report (PCA):\")\n",
        "print(classification_report_pca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB8SCgRO1XNa"
      },
      "source": [
        "#3)Logistic Regression Accuracy (Batch Training): 0.31517241379310346"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BadjmJ4z1dfH",
        "outputId": "7f1c0359-c313-4386-97d1-3c7acfd18fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy (Batch Training): 0.006379310344827587\n",
            "Logistic Regression Classification Report (Batch Training):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00      1979\n",
            "           0       0.00      0.00      0.00        42\n",
            "           1       0.00      0.00      0.00        50\n",
            "           2       0.00      0.00      0.00        43\n",
            "           3       0.00      0.00      0.00        30\n",
            "           4       0.00      0.00      0.00        47\n",
            "           5       0.00      0.00      0.00        39\n",
            "           6       0.00      0.00      0.00        40\n",
            "           7       0.00      0.00      0.00        33\n",
            "           8       0.00      0.00      0.00        43\n",
            "           9       0.00      0.00      0.00        44\n",
            "          10       0.00      0.00      0.00        45\n",
            "          11       0.00      0.00      0.00        46\n",
            "          12       0.00      0.00      0.00        49\n",
            "          13       0.00      0.00      0.00        43\n",
            "          14       0.00      0.00      0.00        31\n",
            "          15       0.00      0.00      0.00        51\n",
            "          16       0.00      0.00      0.00        32\n",
            "          17       0.00      0.00      0.00        45\n",
            "          18       0.00      0.00      0.00        37\n",
            "          19       0.00      0.00      0.00        36\n",
            "          20       0.00      0.00      0.00        40\n",
            "          21       0.01      1.00      0.01        37\n",
            "          22       0.00      0.00      0.00        48\n",
            "          23       0.00      0.00      0.00        46\n",
            "          24       0.00      0.00      0.00        52\n",
            "          25       0.00      0.00      0.00        40\n",
            "          26       0.00      0.00      0.00        36\n",
            "          27       0.00      0.00      0.00        50\n",
            "          28       0.00      0.00      0.00        43\n",
            "          29       0.00      0.00      0.00        44\n",
            "          30       0.00      0.00      0.00        42\n",
            "          31       0.00      0.00      0.00        34\n",
            "          32       0.00      0.00      0.00        43\n",
            "          33       0.00      0.00      0.00        37\n",
            "          34       0.00      0.00      0.00        36\n",
            "          35       0.00      0.00      0.00        43\n",
            "          36       0.00      0.00      0.00        37\n",
            "          37       0.00      0.00      0.00        39\n",
            "          38       0.00      0.00      0.00        40\n",
            "          39       0.00      0.00      0.00        35\n",
            "          40       0.00      0.00      0.00        35\n",
            "          41       0.00      0.00      0.00        32\n",
            "          42       0.00      0.00      0.00        42\n",
            "          43       0.00      0.00      0.00        51\n",
            "          44       0.00      0.00      0.00        36\n",
            "          45       0.00      0.00      0.00        35\n",
            "          46       0.00      0.00      0.00        34\n",
            "          47       0.00      0.00      0.00        35\n",
            "          48       0.00      0.00      0.00        44\n",
            "          49       0.00      0.00      0.00        43\n",
            "          50       0.00      0.00      0.00        38\n",
            "          51       0.00      0.00      0.00        36\n",
            "          52       0.00      0.00      0.00        42\n",
            "          53       0.00      0.00      0.00        43\n",
            "          54       0.00      0.00      0.00        40\n",
            "          55       0.00      0.00      0.00        40\n",
            "          56       0.00      0.00      0.00        38\n",
            "          57       0.00      0.00      0.00        46\n",
            "          58       0.00      0.00      0.00        41\n",
            "          59       0.00      0.00      0.00        46\n",
            "          60       0.00      0.00      0.00        46\n",
            "          61       0.00      0.00      0.00        37\n",
            "          62       0.00      0.00      0.00        38\n",
            "          63       0.00      0.00      0.00        41\n",
            "          64       0.00      0.00      0.00        35\n",
            "          65       0.00      0.00      0.00        28\n",
            "          66       0.00      0.00      0.00        39\n",
            "          67       0.00      0.00      0.00        44\n",
            "          68       0.00      0.00      0.00        37\n",
            "          69       0.00      0.00      0.00        44\n",
            "          70       0.00      0.00      0.00        45\n",
            "          71       0.00      0.00      0.00        42\n",
            "          72       0.00      0.00      0.00        47\n",
            "          73       0.00      0.00      0.00        38\n",
            "          74       0.00      0.00      0.00        33\n",
            "          75       0.00      0.00      0.00        42\n",
            "          76       0.00      0.00      0.00        42\n",
            "          77       0.00      0.00      0.00        35\n",
            "          78       0.00      0.00      0.00        50\n",
            "          79       0.00      0.00      0.00        39\n",
            "          80       0.00      0.00      0.00        40\n",
            "          81       0.00      0.00      0.00        40\n",
            "          82       0.00      0.00      0.00        35\n",
            "          83       0.00      0.00      0.00        35\n",
            "          84       0.00      0.00      0.00        34\n",
            "          85       0.00      0.00      0.00        52\n",
            "          86       0.00      0.00      0.00        38\n",
            "          87       0.00      0.00      0.00        31\n",
            "          88       0.00      0.00      0.00        39\n",
            "          89       0.00      0.00      0.00        33\n",
            "          90       0.00      0.00      0.00        32\n",
            "          91       0.00      0.00      0.00        44\n",
            "          92       0.00      0.00      0.00        38\n",
            "          93       0.00      0.00      0.00        40\n",
            "          94       0.00      0.00      0.00        43\n",
            "\n",
            "    accuracy                           0.01      5800\n",
            "   macro avg       0.00      0.01      0.00      5800\n",
            "weighted avg       0.00      0.01      0.00      5800\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#3.배치 훈련:\n",
        "#배치 크기를 지정하여 모델을 여러 에폭동안 훈련하는 코드입니다.\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# 데이터 분할\n",
        "X_train_batch, X_test_batch, y_train_batch, y_test_batch = train_test_split(\n",
        "    data_total, data_y_total, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Logistic Regression 모델 훈련 (배치 훈련)\n",
        "batch_size = 1000\n",
        "num_epochs = 10\n",
        "\n",
        "clf_LR_batch = SGDClassifier(max_iter=1000, random_state=42)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # 무작위로 배치 생성\n",
        "    indices = np.random.choice(len(X_train_batch), batch_size, replace=False)\n",
        "    X_batch = X_train_batch.iloc[indices]\n",
        "    y_batch = y_train_batch.iloc[indices].values.ravel()\n",
        "\n",
        "    # 모델 훈련\n",
        "    clf_LR_batch.partial_fit(X_batch, y_batch, classes=np.unique(y_train_batch))\n",
        "\n",
        "# 모델 평가\n",
        "y_pred_batch = clf_LR_batch.predict(X_test_batch)\n",
        "accuracy_batch = accuracy_score(y_test_batch, y_pred_batch)\n",
        "classification_report_batch = classification_report(y_test_batch, y_pred_batch)\n",
        "\n",
        "print(\"Logistic Regression Accuracy (Batch Training):\", accuracy_batch)\n",
        "\n",
        "print(\"Logistic Regression Classification Report (Batch Training):\")\n",
        "print(classification_report_batch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzqGmWpF2ZV7"
      },
      "source": [
        "# 2. Decision tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOLw6g7c2zgn"
      },
      "source": [
        "#Decision Tree Accuracy (in %): 59.95%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbzLzrZy2YnH",
        "outputId": "ecc64c55-545a-41db-c519-2f656d358d44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy (in %): 59.69%\n",
            "Decision Tree Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.82      0.83      0.82      1979\n",
            "           0       0.32      0.29      0.30        42\n",
            "           1       0.26      0.16      0.20        50\n",
            "           2       0.65      0.60      0.63        43\n",
            "           3       0.46      0.53      0.49        30\n",
            "           4       0.46      0.34      0.39        47\n",
            "           5       0.41      0.36      0.38        39\n",
            "           6       0.64      0.70      0.67        40\n",
            "           7       0.41      0.52      0.46        33\n",
            "           8       0.59      0.51      0.55        43\n",
            "           9       0.47      0.41      0.44        44\n",
            "          10       0.40      0.44      0.42        45\n",
            "          11       0.51      0.54      0.53        46\n",
            "          12       0.83      0.69      0.76        49\n",
            "          13       0.46      0.37      0.41        43\n",
            "          14       0.30      0.35      0.32        31\n",
            "          15       0.48      0.29      0.37        51\n",
            "          16       0.57      0.50      0.53        32\n",
            "          17       0.42      0.36      0.39        45\n",
            "          18       0.64      0.78      0.71        37\n",
            "          19       0.23      0.25      0.24        36\n",
            "          20       0.86      0.90      0.88        40\n",
            "          21       0.15      0.14      0.14        37\n",
            "          22       0.30      0.21      0.25        48\n",
            "          23       0.67      0.65      0.66        46\n",
            "          24       0.27      0.19      0.22        52\n",
            "          25       0.49      0.53      0.51        40\n",
            "          26       0.64      0.81      0.72        36\n",
            "          27       0.38      0.24      0.29        50\n",
            "          28       0.69      0.67      0.68        43\n",
            "          29       0.64      0.57      0.60        44\n",
            "          30       0.69      0.69      0.69        42\n",
            "          31       0.52      0.65      0.58        34\n",
            "          32       0.48      0.51      0.49        43\n",
            "          33       0.43      0.59      0.50        37\n",
            "          34       0.22      0.19      0.21        36\n",
            "          35       0.62      0.53      0.57        43\n",
            "          36       0.39      0.43      0.41        37\n",
            "          37       0.27      0.26      0.26        39\n",
            "          38       0.49      0.53      0.51        40\n",
            "          39       0.51      0.51      0.51        35\n",
            "          40       0.47      0.54      0.51        35\n",
            "          41       0.54      0.59      0.57        32\n",
            "          42       0.23      0.24      0.23        42\n",
            "          43       0.76      0.73      0.74        51\n",
            "          44       0.82      0.86      0.84        36\n",
            "          45       0.17      0.17      0.17        35\n",
            "          46       0.40      0.50      0.44        34\n",
            "          47       0.28      0.29      0.28        35\n",
            "          48       0.45      0.43      0.44        44\n",
            "          49       0.62      0.74      0.67        43\n",
            "          50       0.56      0.58      0.57        38\n",
            "          51       0.08      0.08      0.08        36\n",
            "          52       0.49      0.48      0.48        42\n",
            "          53       0.26      0.26      0.26        43\n",
            "          54       0.49      0.42      0.45        40\n",
            "          55       0.25      0.30      0.27        40\n",
            "          56       0.82      0.84      0.83        38\n",
            "          57       0.61      0.54      0.57        46\n",
            "          58       0.74      0.63      0.68        41\n",
            "          59       0.43      0.39      0.41        46\n",
            "          60       0.57      0.50      0.53        46\n",
            "          61       0.43      0.41      0.42        37\n",
            "          62       0.42      0.47      0.44        38\n",
            "          63       0.26      0.24      0.25        41\n",
            "          64       0.43      0.51      0.47        35\n",
            "          65       0.35      0.43      0.39        28\n",
            "          66       0.54      0.49      0.51        39\n",
            "          67       0.55      0.48      0.51        44\n",
            "          68       0.53      0.51      0.52        37\n",
            "          69       0.47      0.39      0.42        44\n",
            "          70       0.75      0.89      0.82        45\n",
            "          71       0.31      0.38      0.34        42\n",
            "          72       0.49      0.51      0.50        47\n",
            "          73       0.53      0.71      0.61        38\n",
            "          74       0.35      0.36      0.36        33\n",
            "          75       0.88      0.88      0.88        42\n",
            "          76       0.94      0.81      0.87        42\n",
            "          77       0.21      0.23      0.22        35\n",
            "          78       0.26      0.24      0.25        50\n",
            "          79       0.42      0.36      0.39        39\n",
            "          80       0.57      0.72      0.64        40\n",
            "          81       0.37      0.42      0.40        40\n",
            "          82       0.47      0.51      0.49        35\n",
            "          83       0.62      0.51      0.56        35\n",
            "          84       0.31      0.41      0.35        34\n",
            "          85       0.73      0.52      0.61        52\n",
            "          86       0.81      0.79      0.80        38\n",
            "          87       0.45      0.48      0.47        31\n",
            "          88       0.32      0.31      0.31        39\n",
            "          89       0.17      0.18      0.17        33\n",
            "          90       0.45      0.72      0.55        32\n",
            "          91       0.47      0.41      0.44        44\n",
            "          92       0.37      0.29      0.32        38\n",
            "          93       0.70      0.57      0.63        40\n",
            "          94       0.21      0.23      0.22        43\n",
            "\n",
            "    accuracy                           0.60      5800\n",
            "   macro avg       0.48      0.48      0.48      5800\n",
            "weighted avg       0.60      0.60      0.59      5800\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_total, data_y_total, test_size=0.2, random_state=42)\n",
        "\n",
        "# 결정 트리 모델 생성 및 훈련\n",
        "clf_decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "clf_decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# 모델 평가\n",
        "y_pred_decision_tree = clf_decision_tree.predict(X_test)\n",
        "accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)\n",
        "classification_report_decision_tree = classification_report(y_test, y_pred_decision_tree)\n",
        "\n",
        "print(\"Decision Tree Accuracy (in %): {:.2f}%\".format(accuracy_decision_tree * 100))\n",
        "\n",
        "print(\"Decision Tree Classification Report:\")\n",
        "print(classification_report_decision_tree)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtha0pB09z3I"
      },
      "source": [
        "# 튜닝한 Decision Tree\n",
        "1)\n",
        "Best parameters: {'max_depth': None, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
        "\n",
        "2)\n",
        "Accuracy of the best model: 0.6017241379310345\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqt0Bucc8pS9",
        "outputId": "e8765795-87d0-40e6-cf2f-5d42b397d90a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "Accuracy of the best model: 0.5968965517241379\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Decision Tree 모델과 관련된 하이퍼파라미터 그리드 설정\n",
        "param_grid = {\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 3, 4],\n",
        "    'min_samples_leaf': [1, 2, 3]\n",
        "}\n",
        "\n",
        "# GridSearchCV를 사용하여 최적의 하이퍼파라미터 찾기\n",
        "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 하이퍼파라미터 출력\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# 최적의 모델로 평가\n",
        "tree_best_model = grid_search.best_estimator_\n",
        "tree_accuracy_best_model = tree_best_model.score(X_test, y_test)\n",
        "print(\"Accuracy of the best model:\", tree_accuracy_best_model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 최적의 모델로 예측\n",
        "tree_y_pred = tree_best_model.predict(X_test)\n",
        "\n",
        "# 최적의 모델 평가 및 classification_report 출력\n",
        "tree_classification_report = classification_report(y_test, tree_y_pred)\n",
        "print(\"Decision Tree Classification Report for the Best Model:\")\n",
        "print(tree_classification_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FkEudBnkuXS",
        "outputId": "94ff4bd2-fcad-4e90-ed76-3c8d37c91792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classification Report for the Best Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.82      0.83      0.82      1979\n",
            "           0       0.32      0.29      0.30        42\n",
            "           1       0.26      0.16      0.20        50\n",
            "           2       0.65      0.60      0.63        43\n",
            "           3       0.46      0.53      0.49        30\n",
            "           4       0.46      0.34      0.39        47\n",
            "           5       0.41      0.36      0.38        39\n",
            "           6       0.64      0.70      0.67        40\n",
            "           7       0.41      0.52      0.46        33\n",
            "           8       0.59      0.51      0.55        43\n",
            "           9       0.47      0.41      0.44        44\n",
            "          10       0.40      0.44      0.42        45\n",
            "          11       0.51      0.54      0.53        46\n",
            "          12       0.83      0.69      0.76        49\n",
            "          13       0.46      0.37      0.41        43\n",
            "          14       0.30      0.35      0.32        31\n",
            "          15       0.48      0.29      0.37        51\n",
            "          16       0.57      0.50      0.53        32\n",
            "          17       0.42      0.36      0.39        45\n",
            "          18       0.64      0.78      0.71        37\n",
            "          19       0.23      0.25      0.24        36\n",
            "          20       0.86      0.90      0.88        40\n",
            "          21       0.15      0.14      0.14        37\n",
            "          22       0.30      0.21      0.25        48\n",
            "          23       0.67      0.65      0.66        46\n",
            "          24       0.27      0.19      0.22        52\n",
            "          25       0.49      0.53      0.51        40\n",
            "          26       0.64      0.81      0.72        36\n",
            "          27       0.38      0.24      0.29        50\n",
            "          28       0.69      0.67      0.68        43\n",
            "          29       0.64      0.57      0.60        44\n",
            "          30       0.69      0.69      0.69        42\n",
            "          31       0.52      0.65      0.58        34\n",
            "          32       0.48      0.51      0.49        43\n",
            "          33       0.43      0.59      0.50        37\n",
            "          34       0.22      0.19      0.21        36\n",
            "          35       0.62      0.53      0.57        43\n",
            "          36       0.39      0.43      0.41        37\n",
            "          37       0.27      0.26      0.26        39\n",
            "          38       0.49      0.53      0.51        40\n",
            "          39       0.51      0.51      0.51        35\n",
            "          40       0.47      0.54      0.51        35\n",
            "          41       0.54      0.59      0.57        32\n",
            "          42       0.23      0.24      0.23        42\n",
            "          43       0.76      0.73      0.74        51\n",
            "          44       0.82      0.86      0.84        36\n",
            "          45       0.17      0.17      0.17        35\n",
            "          46       0.40      0.50      0.44        34\n",
            "          47       0.28      0.29      0.28        35\n",
            "          48       0.45      0.43      0.44        44\n",
            "          49       0.62      0.74      0.67        43\n",
            "          50       0.56      0.58      0.57        38\n",
            "          51       0.08      0.08      0.08        36\n",
            "          52       0.49      0.48      0.48        42\n",
            "          53       0.26      0.26      0.26        43\n",
            "          54       0.49      0.42      0.45        40\n",
            "          55       0.25      0.30      0.27        40\n",
            "          56       0.82      0.84      0.83        38\n",
            "          57       0.61      0.54      0.57        46\n",
            "          58       0.74      0.63      0.68        41\n",
            "          59       0.43      0.39      0.41        46\n",
            "          60       0.57      0.50      0.53        46\n",
            "          61       0.43      0.41      0.42        37\n",
            "          62       0.42      0.47      0.44        38\n",
            "          63       0.26      0.24      0.25        41\n",
            "          64       0.43      0.51      0.47        35\n",
            "          65       0.35      0.43      0.39        28\n",
            "          66       0.54      0.49      0.51        39\n",
            "          67       0.55      0.48      0.51        44\n",
            "          68       0.53      0.51      0.52        37\n",
            "          69       0.47      0.39      0.42        44\n",
            "          70       0.75      0.89      0.82        45\n",
            "          71       0.31      0.38      0.34        42\n",
            "          72       0.49      0.51      0.50        47\n",
            "          73       0.53      0.71      0.61        38\n",
            "          74       0.35      0.36      0.36        33\n",
            "          75       0.88      0.88      0.88        42\n",
            "          76       0.94      0.81      0.87        42\n",
            "          77       0.21      0.23      0.22        35\n",
            "          78       0.26      0.24      0.25        50\n",
            "          79       0.42      0.36      0.39        39\n",
            "          80       0.57      0.72      0.64        40\n",
            "          81       0.37      0.42      0.40        40\n",
            "          82       0.47      0.51      0.49        35\n",
            "          83       0.62      0.51      0.56        35\n",
            "          84       0.31      0.41      0.35        34\n",
            "          85       0.73      0.52      0.61        52\n",
            "          86       0.81      0.79      0.80        38\n",
            "          87       0.45      0.48      0.47        31\n",
            "          88       0.32      0.31      0.31        39\n",
            "          89       0.17      0.18      0.17        33\n",
            "          90       0.45      0.72      0.55        32\n",
            "          91       0.47      0.41      0.44        44\n",
            "          92       0.37      0.29      0.32        38\n",
            "          93       0.70      0.57      0.63        40\n",
            "          94       0.21      0.23      0.22        43\n",
            "\n",
            "    accuracy                           0.60      5800\n",
            "   macro avg       0.48      0.48      0.48      5800\n",
            "weighted avg       0.60      0.60      0.59      5800\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIujI7vC3Byn"
      },
      "source": [
        "## 3. Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPruhjh93cIn"
      },
      "source": [
        "#Random Forest Accuracy (in %): 71.16%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OquB0pUH3BUz",
        "outputId": "4637702b-a61a-480c-f4b7-8182bad504f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy (in %): 71.16%\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.78      0.92      0.84      1979\n",
            "           0       0.67      0.43      0.52        42\n",
            "           1       0.50      0.26      0.34        50\n",
            "           2       0.71      0.79      0.75        43\n",
            "           3       0.67      0.60      0.63        30\n",
            "           4       0.60      0.53      0.56        47\n",
            "           5       0.68      0.59      0.63        39\n",
            "           6       0.77      0.75      0.76        40\n",
            "           7       0.62      0.70      0.66        33\n",
            "           8       0.70      0.70      0.70        43\n",
            "           9       0.63      0.55      0.59        44\n",
            "          10       0.82      0.51      0.63        45\n",
            "          11       0.74      0.57      0.64        46\n",
            "          12       0.81      0.80      0.80        49\n",
            "          13       0.56      0.35      0.43        43\n",
            "          14       0.52      0.48      0.50        31\n",
            "          15       0.80      0.73      0.76        51\n",
            "          16       0.59      0.69      0.64        32\n",
            "          17       0.53      0.40      0.46        45\n",
            "          18       0.70      0.89      0.79        37\n",
            "          19       0.45      0.50      0.47        36\n",
            "          20       0.83      0.97      0.90        40\n",
            "          21       0.60      0.16      0.26        37\n",
            "          22       0.45      0.38      0.41        48\n",
            "          23       0.81      0.74      0.77        46\n",
            "          24       0.48      0.27      0.35        52\n",
            "          25       0.68      0.65      0.67        40\n",
            "          26       0.70      0.78      0.74        36\n",
            "          27       0.75      0.36      0.49        50\n",
            "          28       0.82      0.65      0.73        43\n",
            "          29       0.74      0.70      0.72        44\n",
            "          30       0.74      0.76      0.75        42\n",
            "          31       0.68      0.62      0.65        34\n",
            "          32       0.68      0.60      0.64        43\n",
            "          33       0.83      0.78      0.81        37\n",
            "          34       0.32      0.33      0.33        36\n",
            "          35       0.75      0.77      0.76        43\n",
            "          36       0.59      0.59      0.59        37\n",
            "          37       0.55      0.31      0.39        39\n",
            "          38       0.57      0.57      0.57        40\n",
            "          39       0.56      0.57      0.56        35\n",
            "          40       0.56      0.69      0.62        35\n",
            "          41       0.83      0.75      0.79        32\n",
            "          42       0.63      0.57      0.60        42\n",
            "          43       0.90      0.84      0.87        51\n",
            "          44       0.81      0.94      0.87        36\n",
            "          45       0.47      0.43      0.45        35\n",
            "          46       0.60      0.76      0.68        34\n",
            "          47       0.38      0.34      0.36        35\n",
            "          48       0.59      0.39      0.47        44\n",
            "          49       0.84      0.86      0.85        43\n",
            "          50       0.68      0.66      0.67        38\n",
            "          51       0.32      0.22      0.26        36\n",
            "          52       0.73      0.52      0.61        42\n",
            "          53       0.58      0.35      0.43        43\n",
            "          54       0.73      0.75      0.74        40\n",
            "          55       0.48      0.40      0.44        40\n",
            "          56       0.94      0.84      0.89        38\n",
            "          57       0.70      0.70      0.70        46\n",
            "          58       0.78      0.71      0.74        41\n",
            "          59       0.71      0.63      0.67        46\n",
            "          60       0.73      0.72      0.73        46\n",
            "          61       0.59      0.62      0.61        37\n",
            "          62       0.66      0.76      0.71        38\n",
            "          63       0.48      0.34      0.40        41\n",
            "          64       0.59      0.66      0.62        35\n",
            "          65       0.38      0.54      0.45        28\n",
            "          66       0.57      0.64      0.60        39\n",
            "          67       0.76      0.66      0.71        44\n",
            "          68       0.67      0.59      0.63        37\n",
            "          69       0.55      0.52      0.53        44\n",
            "          70       0.91      0.96      0.93        45\n",
            "          71       0.63      0.45      0.53        42\n",
            "          72       0.73      0.64      0.68        47\n",
            "          73       0.60      0.82      0.69        38\n",
            "          74       0.39      0.52      0.44        33\n",
            "          75       0.85      0.95      0.90        42\n",
            "          76       0.92      0.86      0.89        42\n",
            "          77       0.44      0.31      0.37        35\n",
            "          78       0.53      0.34      0.41        50\n",
            "          79       0.52      0.31      0.39        39\n",
            "          80       0.72      0.85      0.78        40\n",
            "          81       0.65      0.65      0.65        40\n",
            "          82       0.70      0.60      0.65        35\n",
            "          83       0.76      0.71      0.74        35\n",
            "          84       0.59      0.65      0.62        34\n",
            "          85       0.84      0.79      0.81        52\n",
            "          86       0.90      0.95      0.92        38\n",
            "          87       0.67      0.58      0.62        31\n",
            "          88       0.81      0.67      0.73        39\n",
            "          89       0.64      0.42      0.51        33\n",
            "          90       0.60      0.75      0.67        32\n",
            "          91       0.57      0.64      0.60        44\n",
            "          92       0.57      0.32      0.41        38\n",
            "          93       0.88      0.72      0.79        40\n",
            "          94       0.48      0.28      0.35        43\n",
            "\n",
            "    accuracy                           0.71      5800\n",
            "   macro avg       0.66      0.61      0.62      5800\n",
            "weighted avg       0.70      0.71      0.70      5800\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 랜덤 포레스트 모델 생성 및 훈련\n",
        "clf_random_forest = RandomForestClassifier(random_state=42)\n",
        "clf_random_forest.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# 모델 평가\n",
        "y_pred_random_forest = clf_random_forest.predict(X_test)\n",
        "accuracy_random_forest = accuracy_score(y_test, y_pred_random_forest)\n",
        "classification_report_random_forest = classification_report(y_test, y_pred_random_forest)\n",
        "\n",
        "print(\"Random Forest Accuracy (in %): {:.2f}%\".format(accuracy_random_forest * 100))\n",
        "\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report_random_forest)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "원래는 binary와 같이 feature 7개로 진행했으나 결과가 좋지 않았다. 13개의 feature 전부 사용하면 과적합 문제가 생길 것 같아서 중요도 검사를 따로 진행했다."
      ],
      "metadata": {
        "id": "MOxY2xVaBoqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = clf_random_forest.feature_importances_\n",
        "num_features = len(feature_importance)\n",
        "\n",
        "# 특성 중요도 출력\n",
        "for i in range(num_features):\n",
        "    print(f\"Feature {i + 1} importance: {feature_importance[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH9ZO1vj5LEw",
        "outputId": "15d77853-b4f8-4b3a-bd15-c11787542946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 1 importance: 0.08014748879310223\n",
            "Feature 2 importance: 0.17460484298053447\n",
            "Feature 3 importance: 0.08203407857980052\n",
            "Feature 4 importance: 0.0759151780112168\n",
            "Feature 5 importance: 0.07633207567829499\n",
            "Feature 6 importance: 0.06585863956517138\n",
            "Feature 7 importance: 0.07470483673401732\n",
            "Feature 8 importance: 0.048872228406383146\n",
            "Feature 9 importance: 0.08217429328035099\n",
            "Feature 10 importance: 0.08101040093739358\n",
            "Feature 11 importance: 0.03574390690169854\n",
            "Feature 12 importance: 0.06888110287652849\n",
            "Feature 13 importance: 0.053720927255507575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# RandomForestClassifier 모델 생성 (criterion='entropy'로 설정)\n",
        "clf_random_forest_entropy = RandomForestClassifier(random_state=42, criterion='entropy')\n",
        "clf_random_forest_entropy.fit(X_train, y_train.ravel())\n",
        "\n",
        "# 특성 중요도 (Entropy) 출력\n",
        "feature_importance_entropy = clf_random_forest_entropy.feature_importances_\n",
        "\n",
        "for i, importance in enumerate(feature_importance_entropy):\n",
        "    print(f\"Feature {i + 1} importance (Entropy): {importance}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urjGZuIh5i_W",
        "outputId": "39f35b2f-7c1f-4407-aa5f-d2927d1c131d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 1 importance (Entropy): 0.07624400386397329\n",
            "Feature 2 importance (Entropy): 0.12832974956999255\n",
            "Feature 3 importance (Entropy): 0.10210637065563802\n",
            "Feature 4 importance (Entropy): 0.09671005313940702\n",
            "Feature 5 importance (Entropy): 0.09622189408277418\n",
            "Feature 6 importance (Entropy): 0.049700345505096305\n",
            "Feature 7 importance (Entropy): 0.10017825051594402\n",
            "Feature 8 importance (Entropy): 0.029310696669663655\n",
            "Feature 9 importance (Entropy): 0.10014307429015896\n",
            "Feature 10 importance (Entropy): 0.09935673059834187\n",
            "Feature 11 importance (Entropy): 0.04166101092730532\n",
            "Feature 12 importance (Entropy): 0.04726137795485427\n",
            "Feature 13 importance (Entropy): 0.03277644222685048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 특성별 Gini 중요도와 Entropy 중요도를 리스트로 표현\n",
        "gini_importance = [\n",
        "    0.08014748879310223, 0.17460484298053447, 0.08203407857980052,\n",
        "    0.0759151780112168, 0.07633207567829499, 0.06585863956517138,\n",
        "    0.07470483673401732, 0.048872228406383146, 0.08217429328035099,\n",
        "    0.08101040093739358, 0.03574390690169854, 0.06888110287652849,\n",
        "    0.053720927255507575\n",
        "]\n",
        "\n",
        "entropy_importance = [\n",
        "    0.07624400386397329, 0.12832974956999255, 0.10210637065563802,\n",
        "    0.09671005313940702, 0.09622189408277418, 0.049700345505096305,\n",
        "    0.10017825051594402, 0.029310696669663655, 0.10014307429015896,\n",
        "    0.09935673059834187, 0.04166101092730532, 0.04726137795485427,\n",
        "    0.03277644222685048\n",
        "]\n",
        "\n",
        "# 각 특성별 Gini와 Entropy 중요도 합산\n",
        "combined_importance = [gini + entropy for gini, entropy in zip(gini_importance, entropy_importance)]\n",
        "\n",
        "# 각 특성별 평균 중요도 계산\n",
        "avg_combined_importance = [importance / 2 for importance in combined_importance]\n",
        "\n",
        "# 결과 출력\n",
        "for idx, importance in enumerate(avg_combined_importance):\n",
        "    print(f\"Feature {idx + 1} importance (Combined Gini and Entropy): {importance}\")# 각 특성별 Gini 중요도와 Entropy 중요도를 리스트로 표현\n",
        "gini_importance = [\n",
        "    0.08014748879310223, 0.17460484298053447, 0.08203407857980052,\n",
        "    0.0759151780112168, 0.07633207567829499, 0.06585863956517138,\n",
        "    0.07470483673401732, 0.048872228406383146, 0.08217429328035099,\n",
        "    0.08101040093739358, 0.03574390690169854, 0.06888110287652849,\n",
        "    0.053720927255507575\n",
        "]\n",
        "\n",
        "entropy_importance = [\n",
        "    0.07624400386397329, 0.12832974956999255, 0.10210637065563802,\n",
        "    0.09671005313940702, 0.09622189408277418, 0.049700345505096305,\n",
        "    0.10017825051594402, 0.029310696669663655, 0.10014307429015896,\n",
        "    0.09935673059834187, 0.04166101092730532, 0.04726137795485427,\n",
        "    0.03277644222685048\n",
        "]\n",
        "\n",
        "# 각 특성별 Gini와 Entropy 중요도 합산\n",
        "combined_importance = [gini + entropy for gini, entropy in zip(gini_importance, entropy_importance)]\n",
        "\n",
        "# 각 특성별 평균 중요도 계산\n",
        "avg_combined_importance = [importance / 2 for importance in combined_importance]\n",
        "\n",
        "\n",
        "# 결과 출력\n",
        "for idx, importance in enumerate(avg_combined_importance):\n",
        "    print(f\"Feature {idx + 1} importance (Combined Gini and Entropy): {importance}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz6XPr0968CS",
        "outputId": "ae93bb1f-5f5f-4351-a80a-2d394ff1c968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 1 importance (Combined Gini and Entropy): 0.07819574632853776\n",
            "Feature 2 importance (Combined Gini and Entropy): 0.1514672962752635\n",
            "Feature 3 importance (Combined Gini and Entropy): 0.09207022461771927\n",
            "Feature 4 importance (Combined Gini and Entropy): 0.08631261557531192\n",
            "Feature 5 importance (Combined Gini and Entropy): 0.08627698488053459\n",
            "Feature 6 importance (Combined Gini and Entropy): 0.05777949253513384\n",
            "Feature 7 importance (Combined Gini and Entropy): 0.08744154362498066\n",
            "Feature 8 importance (Combined Gini and Entropy): 0.0390914625380234\n",
            "Feature 9 importance (Combined Gini and Entropy): 0.09115868378525498\n",
            "Feature 10 importance (Combined Gini and Entropy): 0.09018356576786772\n",
            "Feature 11 importance (Combined Gini and Entropy): 0.03870245891450193\n",
            "Feature 12 importance (Combined Gini and Entropy): 0.05807124041569138\n",
            "Feature 13 importance (Combined Gini and Entropy): 0.04324868474117903\n",
            "Feature 1 importance (Combined Gini and Entropy): 0.07819574632853776\n",
            "Feature 2 importance (Combined Gini and Entropy): 0.1514672962752635\n",
            "Feature 3 importance (Combined Gini and Entropy): 0.09207022461771927\n",
            "Feature 4 importance (Combined Gini and Entropy): 0.08631261557531192\n",
            "Feature 5 importance (Combined Gini and Entropy): 0.08627698488053459\n",
            "Feature 6 importance (Combined Gini and Entropy): 0.05777949253513384\n",
            "Feature 7 importance (Combined Gini and Entropy): 0.08744154362498066\n",
            "Feature 8 importance (Combined Gini and Entropy): 0.0390914625380234\n",
            "Feature 9 importance (Combined Gini and Entropy): 0.09115868378525498\n",
            "Feature 10 importance (Combined Gini and Entropy): 0.09018356576786772\n",
            "Feature 11 importance (Combined Gini and Entropy): 0.03870245891450193\n",
            "Feature 12 importance (Combined Gini and Entropy): 0.05807124041569138\n",
            "Feature 13 importance (Combined Gini and Entropy): 0.04324868474117903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Feature 1 importance (Combined Gini and Entropy): 0.07819574632853776\n",
        "\n",
        "Feature 2 importance (Combined Gini and Entropy): 0.1514672962752635\n",
        "\n",
        "Feature 3 importance (Combined Gini and Entropy): 0.09207022461771927\n",
        "\n",
        "Feature 4 importance (Combined Gini and Entropy): 0.08631261557531192\n",
        "\n",
        "Feature 5 importance (Combined Gini and Entropy): 0.08627698488053459\n",
        "\n",
        "Feature 6 importance (Combined Gini and Entropy): 0.05777949253513384\n",
        "\n",
        "Feature 7 importance (Combined Gini and Entropy): 0.08744154362498066\n",
        "\n",
        "Feature 8 importance (Combined Gini and Entropy): 0.0390914625380234\n",
        "\n",
        "Feature 9 importance (Combined Gini and Entropy): 0.09115868378525498\n",
        "\n",
        "Feature 10 importance (Combined Gini and Entropy): 0.09018356576786772\n",
        "\n",
        "Feature 11 importance (Combined Gini and Entropy): 0.03870245891450193\n",
        "\n",
        "Feature 12 importance (Combined Gini and Entropy): 0.05807124041569138\n",
        "\n",
        "Feature 13 importance (Combined Gini and Entropy): 0.04324868474117903\n",
        "\n",
        "위에서 0.05 이하인 것들을 추리면 X8, X11, X13 정도다. 즉 feature 1. 3. 5. 6. 7. 8. 9. 12. 14. 16만 남겨두면 된다.  \n",
        "\n",
        "다시 처음으로 돌아가서 주석 처리하고 다시 돌려보겠다.\n"
      ],
      "metadata": {
        "id": "Ds-Zo-e77OXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "피쳐 처리 전 : Random Forest Accuracy (in %): 72.31%\n",
        "피쳐 처리 후 : 71.16"
      ],
      "metadata": {
        "id": "JxUe_JSP9NCI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#튜닝 : Accuracy of the best model: 0.7222413793103448\n",
        "\n",
        "Best parameters: {'max_depth': 28, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 766}"
      ],
      "metadata": {
        "id": "UiKu2s8lrspX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXerjxAw9XC6",
        "outputId": "c5e01f30-be50-471f-b5ad-246b6fe31b99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'max_depth': 28, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 766}\n",
            "Accuracy of the best model: 0.7222413793103448\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import randint\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# 튜닝할 하이퍼파라미터 범위 설정\n",
        "param_dist = {\n",
        "    'n_estimators': randint(400, 800),  # 100에서 1000 사이의 랜덤한 정수\n",
        "    'max_depth': [None] + list(randint(10, 30).rvs(5)),  # None과 10에서 30 사이의 랜덤한 정수\n",
        "    'min_samples_split': randint(3, 15),  # 2에서 20 사이의 랜덤한 정수\n",
        "    'min_samples_leaf': randint(1, 5),   # 1에서 10 사이의 랜덤한 정수\n",
        "    'max_features': ['sqrt', 'auto']\n",
        "}\n",
        "\n",
        "# RandomForestClassifier 생성\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# RandomizedSearchCV를 사용하여 튜닝\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=50, cv=5, random_state=42)\n",
        "random_search.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# 최적의 하이퍼파라미터 출력\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "\n",
        "# 최적의 모델로 평가\n",
        "best_model = random_search.best_estimator_\n",
        "accuracy_best_model = best_model.score(X_test, y_test)\n",
        "print(\"Accuracy of the best model:\", accuracy_best_model)\n",
        "\n",
        "#이거 오래걸림..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 최적의 모델로 예측\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# classification_report 출력\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5DiRTz1ih04",
        "outputId": "3e0995ff-a8d6-4487-9855-a7db88cd399b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.79      0.92      0.85      2058\n",
            "           0       0.66      0.56      0.61        41\n",
            "           1       0.65      0.49      0.56        35\n",
            "           2       0.64      0.79      0.71        43\n",
            "           3       0.77      0.56      0.65        41\n",
            "           4       0.63      0.50      0.56        44\n",
            "           5       0.73      0.60      0.66        40\n",
            "           6       0.72      0.90      0.80        31\n",
            "           7       0.72      0.62      0.67        42\n",
            "           8       0.81      0.91      0.86        43\n",
            "           9       0.61      0.54      0.57        37\n",
            "          10       0.63      0.44      0.52        43\n",
            "          11       0.49      0.57      0.52        30\n",
            "          12       0.81      0.71      0.76        42\n",
            "          13       0.62      0.41      0.49        37\n",
            "          14       0.58      0.51      0.55        35\n",
            "          15       0.61      0.70      0.65        33\n",
            "          16       0.65      0.56      0.60        39\n",
            "          17       0.57      0.61      0.59        33\n",
            "          18       0.88      0.83      0.85        46\n",
            "          19       0.49      0.44      0.46        43\n",
            "          20       0.92      0.94      0.93        51\n",
            "          21       0.60      0.12      0.21        48\n",
            "          22       0.49      0.45      0.47        42\n",
            "          23       0.89      0.86      0.88        29\n",
            "          24       0.41      0.23      0.30        56\n",
            "          25       0.79      0.60      0.68        45\n",
            "          26       0.77      0.86      0.81        43\n",
            "          27       0.75      0.35      0.48        34\n",
            "          28       0.77      0.73      0.75        37\n",
            "          29       0.64      0.72      0.67        39\n",
            "          30       0.78      0.76      0.77        41\n",
            "          31       0.82      0.59      0.69        56\n",
            "          32       0.65      0.60      0.62        40\n",
            "          33       0.76      0.65      0.70        43\n",
            "          34       0.36      0.26      0.30        31\n",
            "          35       0.80      0.86      0.83        42\n",
            "          36       0.63      0.61      0.62        44\n",
            "          37       0.60      0.51      0.55        35\n",
            "          38       0.72      0.82      0.77        34\n",
            "          39       0.71      0.56      0.62        43\n",
            "          40       0.60      0.54      0.57        39\n",
            "          41       0.86      0.79      0.83        39\n",
            "          42       0.50      0.60      0.55        40\n",
            "          43       0.74      0.84      0.79        44\n",
            "          44       0.79      1.00      0.88        37\n",
            "          45       0.48      0.23      0.31        44\n",
            "          46       0.78      0.68      0.73        41\n",
            "          47       0.53      0.30      0.38        30\n",
            "          48       0.58      0.33      0.42        46\n",
            "          49       0.79      0.82      0.81        28\n",
            "          50       0.64      0.72      0.68        40\n",
            "          51       0.45      0.28      0.35        32\n",
            "          52       0.77      0.59      0.67        46\n",
            "          53       0.83      0.47      0.60        51\n",
            "          54       0.69      0.57      0.62        35\n",
            "          55       0.50      0.45      0.48        42\n",
            "          56       0.95      0.86      0.90        42\n",
            "          57       0.69      0.61      0.65        41\n",
            "          58       0.62      0.90      0.74        39\n",
            "          59       0.74      0.66      0.70        44\n",
            "          60       0.69      0.69      0.69        48\n",
            "          61       0.49      0.56      0.52        34\n",
            "          62       0.74      0.78      0.76        36\n",
            "          63       0.63      0.46      0.54        41\n",
            "          64       0.54      0.57      0.56        44\n",
            "          65       0.59      0.53      0.56        38\n",
            "          66       0.59      0.62      0.61        37\n",
            "          67       0.68      0.85      0.75        27\n",
            "          68       0.56      0.40      0.47        35\n",
            "          69       0.72      0.51      0.60        45\n",
            "          70       0.84      0.93      0.88        40\n",
            "          71       0.56      0.51      0.53        39\n",
            "          72       0.39      0.45      0.42        29\n",
            "          73       0.68      0.77      0.72        30\n",
            "          74       0.44      0.61      0.51        33\n",
            "          75       0.93      0.93      0.93        41\n",
            "          76       0.92      0.88      0.90        41\n",
            "          77       0.39      0.31      0.35        35\n",
            "          78       0.40      0.32      0.35        38\n",
            "          79       0.50      0.41      0.45        39\n",
            "          80       0.67      0.74      0.70        42\n",
            "          81       0.68      0.61      0.64        41\n",
            "          82       0.76      0.55      0.64        40\n",
            "          83       0.75      0.75      0.75        40\n",
            "          84       0.57      0.57      0.57        37\n",
            "          85       0.73      0.88      0.80        40\n",
            "          86       0.91      0.91      0.91        46\n",
            "          87       0.65      0.81      0.72        37\n",
            "          88       0.64      0.45      0.53        40\n",
            "          89       0.43      0.43      0.43        35\n",
            "          90       0.58      0.54      0.56        35\n",
            "          91       0.75      0.73      0.74        41\n",
            "          92       0.52      0.47      0.49        30\n",
            "          93       0.77      0.79      0.78        42\n",
            "          94       0.59      0.37      0.46        35\n",
            "\n",
            "    accuracy                           0.72      5800\n",
            "   macro avg       0.66      0.62      0.63      5800\n",
            "weighted avg       0.71      0.72      0.71      5800\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 최적의 하이퍼파라미터로 모델 생성\n",
        "best_model = RandomForestClassifier(max_depth=28, max_features='auto', min_samples_leaf=2, min_samples_split=4, n_estimators=100, random_state=42)\n",
        "\n",
        "# 모델 학습\n",
        "best_model.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# 테스트 데이터에 대해 모델 평가\n",
        "accuracy_best_model = best_model.score(X_test, y_test)\n",
        "print(\"Accuracy of the best model:\", accuracy_best_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fckNtlTILhvG",
        "outputId": "923eae86-1702-4871-edf0-0923f01f3e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the best model: 0.713103448275862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 모델 예측\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# classification_report를 이용하여 precision, recall, f1-score 등 확인\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9yDUF4rMSSG",
        "outputId": "ac08f2e9-d55a-4678-8393-817660a4a7af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.78      0.92      0.84      1979\n",
            "           0       0.65      0.48      0.55        42\n",
            "           1       0.58      0.28      0.38        50\n",
            "           2       0.70      0.77      0.73        43\n",
            "           3       0.62      0.60      0.61        30\n",
            "           4       0.61      0.57      0.59        47\n",
            "           5       0.72      0.54      0.62        39\n",
            "           6       0.76      0.78      0.77        40\n",
            "           7       0.62      0.70      0.66        33\n",
            "           8       0.68      0.70      0.69        43\n",
            "           9       0.62      0.57      0.60        44\n",
            "          10       0.81      0.49      0.61        45\n",
            "          11       0.69      0.54      0.61        46\n",
            "          12       0.83      0.78      0.80        49\n",
            "          13       0.58      0.33      0.42        43\n",
            "          14       0.50      0.42      0.46        31\n",
            "          15       0.77      0.73      0.75        51\n",
            "          16       0.63      0.69      0.66        32\n",
            "          17       0.57      0.44      0.50        45\n",
            "          18       0.73      0.89      0.80        37\n",
            "          19       0.53      0.53      0.53        36\n",
            "          20       0.88      0.95      0.92        40\n",
            "          21       0.54      0.19      0.28        37\n",
            "          22       0.46      0.35      0.40        48\n",
            "          23       0.84      0.80      0.82        46\n",
            "          24       0.59      0.25      0.35        52\n",
            "          25       0.66      0.62      0.64        40\n",
            "          26       0.67      0.81      0.73        36\n",
            "          27       0.83      0.38      0.52        50\n",
            "          28       0.84      0.63      0.72        43\n",
            "          29       0.75      0.75      0.75        44\n",
            "          30       0.78      0.83      0.80        42\n",
            "          31       0.66      0.62      0.64        34\n",
            "          32       0.66      0.63      0.64        43\n",
            "          33       0.74      0.78      0.76        37\n",
            "          34       0.35      0.36      0.36        36\n",
            "          35       0.71      0.74      0.73        43\n",
            "          36       0.62      0.62      0.62        37\n",
            "          37       0.57      0.31      0.40        39\n",
            "          38       0.54      0.53      0.53        40\n",
            "          39       0.54      0.54      0.54        35\n",
            "          40       0.58      0.74      0.65        35\n",
            "          41       0.79      0.69      0.73        32\n",
            "          42       0.61      0.55      0.57        42\n",
            "          43       0.84      0.82      0.83        51\n",
            "          44       0.83      0.94      0.88        36\n",
            "          45       0.54      0.43      0.48        35\n",
            "          46       0.72      0.76      0.74        34\n",
            "          47       0.44      0.34      0.39        35\n",
            "          48       0.72      0.41      0.52        44\n",
            "          49       0.84      0.84      0.84        43\n",
            "          50       0.70      0.68      0.69        38\n",
            "          51       0.36      0.25      0.30        36\n",
            "          52       0.70      0.50      0.58        42\n",
            "          53       0.52      0.28      0.36        43\n",
            "          54       0.77      0.75      0.76        40\n",
            "          55       0.53      0.40      0.46        40\n",
            "          56       0.94      0.84      0.89        38\n",
            "          57       0.71      0.70      0.70        46\n",
            "          58       0.76      0.76      0.76        41\n",
            "          59       0.71      0.63      0.67        46\n",
            "          60       0.81      0.76      0.79        46\n",
            "          61       0.53      0.65      0.59        37\n",
            "          62       0.62      0.79      0.70        38\n",
            "          63       0.65      0.37      0.47        41\n",
            "          64       0.64      0.66      0.65        35\n",
            "          65       0.36      0.50      0.42        28\n",
            "          66       0.56      0.64      0.60        39\n",
            "          67       0.77      0.68      0.72        44\n",
            "          68       0.70      0.62      0.66        37\n",
            "          69       0.60      0.57      0.58        44\n",
            "          70       0.93      0.93      0.93        45\n",
            "          71       0.69      0.52      0.59        42\n",
            "          72       0.79      0.66      0.72        47\n",
            "          73       0.60      0.84      0.70        38\n",
            "          74       0.43      0.58      0.49        33\n",
            "          75       0.87      0.93      0.90        42\n",
            "          76       0.97      0.86      0.91        42\n",
            "          77       0.54      0.40      0.46        35\n",
            "          78       0.57      0.34      0.42        50\n",
            "          79       0.57      0.33      0.42        39\n",
            "          80       0.72      0.85      0.78        40\n",
            "          81       0.77      0.68      0.72        40\n",
            "          82       0.66      0.54      0.59        35\n",
            "          83       0.65      0.69      0.67        35\n",
            "          84       0.62      0.71      0.66        34\n",
            "          85       0.86      0.83      0.84        52\n",
            "          86       0.84      0.95      0.89        38\n",
            "          87       0.66      0.61      0.63        31\n",
            "          88       0.76      0.64      0.69        39\n",
            "          89       0.58      0.42      0.49        33\n",
            "          90       0.58      0.78      0.67        32\n",
            "          91       0.55      0.64      0.59        44\n",
            "          92       0.60      0.32      0.41        38\n",
            "          93       0.83      0.75      0.79        40\n",
            "          94       0.50      0.30      0.38        43\n",
            "\n",
            "    accuracy                           0.72      5800\n",
            "   macro avg       0.67      0.62      0.63      5800\n",
            "weighted avg       0.71      0.72      0.70      5800\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww_eQuNU3kEz"
      },
      "source": [
        "## 4. k-NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqGrIqwY39e3"
      },
      "source": [
        "#KNN Accuracy (in %): 44.95%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V20QV2zt3CQI",
        "outputId": "c34e85e1-77af-4314-a5a6-3e0dd6f4acaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy (in %): 44.95%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# KNN 모델 생성 및 훈련\n",
        "clf_knn = KNeighborsClassifier()\n",
        "clf_knn.fit(X_train, y_train)\n",
        "\n",
        "# y_train, y_test를 1차원 배열로 변환\n",
        "y_train = np.ravel(y_train)\n",
        "y_test = np.ravel(y_test)\n",
        "\n",
        "# 변환 후 KNN 모델 훈련 및 예측\n",
        "clf_knn.fit(X_train, y_train)\n",
        "y_pred_knn = clf_knn.predict(X_test)\n",
        "\n",
        "# 모델 평가\n",
        "y_pred_knn = clf_knn.predict(X_test)\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "classification_report_knn = classification_report(y_test, y_pred_knn)\n",
        "\n",
        "print(\"KNN Accuracy (in %): {:.2f}%\".format(accuracy_knn * 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1K7brq_-HX7"
      },
      "source": [
        "#튜닝한 K-NN\n",
        "\n",
        "1)\n",
        "Best K value: 8\n",
        "\n",
        "Tuned KNN Accuracy (in %): 46.48%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSZUwwO1-GSQ",
        "outputId": "fd0c7a95-7c6b-4878-e24c-3812f7bab2d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best K value: 8\n",
            "Tuned KNN Accuracy (in %): 46.48%\n",
            "Classification Report for Tuned KNN:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.69      0.92      0.79      2058\n",
            "           0       0.09      0.07      0.08        41\n",
            "           1       0.11      0.14      0.12        35\n",
            "           2       0.26      0.49      0.34        43\n",
            "           3       0.33      0.37      0.35        41\n",
            "           4       0.36      0.23      0.28        44\n",
            "           5       0.07      0.07      0.07        40\n",
            "           6       0.04      0.06      0.05        31\n",
            "           7       0.22      0.26      0.24        42\n",
            "           8       0.34      0.37      0.36        43\n",
            "           9       0.12      0.14      0.12        37\n",
            "          10       0.16      0.07      0.10        43\n",
            "          11       0.11      0.17      0.13        30\n",
            "          12       0.54      0.50      0.52        42\n",
            "          13       0.20      0.22      0.21        37\n",
            "          14       0.27      0.40      0.33        35\n",
            "          15       0.35      0.24      0.29        33\n",
            "          16       0.43      0.54      0.48        39\n",
            "          17       0.03      0.03      0.03        33\n",
            "          18       0.43      0.43      0.43        46\n",
            "          19       0.11      0.09      0.10        43\n",
            "          20       0.54      0.57      0.55        51\n",
            "          21       0.25      0.04      0.07        48\n",
            "          22       0.10      0.07      0.08        42\n",
            "          23       0.16      0.28      0.21        29\n",
            "          24       0.07      0.02      0.03        56\n",
            "          25       0.49      0.38      0.42        45\n",
            "          26       0.62      0.56      0.59        43\n",
            "          27       0.14      0.09      0.11        34\n",
            "          28       0.33      0.35      0.34        37\n",
            "          29       0.11      0.15      0.12        39\n",
            "          30       0.53      0.49      0.51        41\n",
            "          31       0.57      0.14      0.23        56\n",
            "          32       0.09      0.10      0.09        40\n",
            "          33       0.30      0.26      0.28        43\n",
            "          34       0.13      0.13      0.13        31\n",
            "          35       0.23      0.26      0.25        42\n",
            "          36       0.13      0.11      0.12        44\n",
            "          37       0.09      0.03      0.04        35\n",
            "          38       0.19      0.18      0.18        34\n",
            "          39       0.21      0.16      0.18        43\n",
            "          40       0.14      0.10      0.12        39\n",
            "          41       0.26      0.26      0.26        39\n",
            "          42       0.09      0.07      0.08        40\n",
            "          43       0.26      0.23      0.24        44\n",
            "          44       0.49      0.68      0.57        37\n",
            "          45       0.17      0.11      0.14        44\n",
            "          46       0.26      0.12      0.17        41\n",
            "          47       0.25      0.03      0.06        30\n",
            "          48       0.16      0.13      0.14        46\n",
            "          49       0.21      0.21      0.21        28\n",
            "          50       0.15      0.10      0.12        40\n",
            "          51       0.12      0.06      0.08        32\n",
            "          52       0.25      0.13      0.17        46\n",
            "          53       0.20      0.06      0.09        51\n",
            "          54       0.07      0.06      0.06        35\n",
            "          55       0.20      0.10      0.13        42\n",
            "          56       0.44      0.57      0.50        42\n",
            "          57       0.29      0.12      0.17        41\n",
            "          58       0.29      0.33      0.31        39\n",
            "          59       0.21      0.14      0.16        44\n",
            "          60       0.21      0.12      0.16        48\n",
            "          61       0.03      0.03      0.03        34\n",
            "          62       0.24      0.14      0.18        36\n",
            "          63       0.05      0.02      0.03        41\n",
            "          64       0.15      0.11      0.13        44\n",
            "          65       0.14      0.11      0.12        38\n",
            "          66       0.28      0.35      0.31        37\n",
            "          67       0.31      0.30      0.30        27\n",
            "          68       0.08      0.03      0.04        35\n",
            "          69       0.11      0.04      0.06        45\n",
            "          70       0.67      0.80      0.73        40\n",
            "          71       0.13      0.05      0.07        39\n",
            "          72       0.12      0.14      0.13        29\n",
            "          73       0.28      0.50      0.36        30\n",
            "          74       0.23      0.21      0.22        33\n",
            "          75       0.81      0.71      0.75        41\n",
            "          76       0.64      0.78      0.70        41\n",
            "          77       0.00      0.00      0.00        35\n",
            "          78       0.07      0.03      0.04        38\n",
            "          79       0.30      0.08      0.12        39\n",
            "          80       0.41      0.26      0.32        42\n",
            "          81       0.17      0.15      0.16        41\n",
            "          82       0.60      0.45      0.51        40\n",
            "          83       0.23      0.12      0.16        40\n",
            "          84       0.11      0.11      0.11        37\n",
            "          85       0.49      0.42      0.45        40\n",
            "          86       0.55      0.50      0.52        46\n",
            "          87       0.15      0.16      0.15        37\n",
            "          88       0.24      0.10      0.14        40\n",
            "          89       0.18      0.11      0.14        35\n",
            "          90       0.25      0.11      0.16        35\n",
            "          91       0.33      0.22      0.26        41\n",
            "          92       0.08      0.03      0.05        30\n",
            "          93       0.22      0.10      0.13        42\n",
            "          94       0.08      0.03      0.04        35\n",
            "\n",
            "    accuracy                           0.46      5800\n",
            "   macro avg       0.25      0.22      0.22      5800\n",
            "weighted avg       0.41      0.46      0.42      5800\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 탐색할 이웃 수의 범위 지정\n",
        "param_grid = {'n_neighbors': range(1, 21)}\n",
        "\n",
        "# 그리드 서치를 사용하여 최적의 이웃 수 찾기\n",
        "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 이웃 수 출력\n",
        "print(\"Best K value:\", grid_search.best_params_['n_neighbors'])\n",
        "\n",
        "# 최적의 이웃 수로 모델 재훈련\n",
        "best_k = grid_search.best_params_['n_neighbors']\n",
        "clf_knn_tuned = KNeighborsClassifier(n_neighbors=best_k)\n",
        "clf_knn_tuned.fit(X_train, y_train)\n",
        "\n",
        "# 튜닝된 모델 평가\n",
        "y_pred_knn_tuned = clf_knn_tuned.predict(X_test)\n",
        "accuracy_knn_tuned = accuracy_score(y_test, y_pred_knn_tuned)\n",
        "classification_report_knn_tuned = classification_report(y_test, y_pred_knn_tuned)\n",
        "\n",
        "print(\"Tuned KNN Accuracy (in %): {:.2f}%\".format(accuracy_knn_tuned * 100))\n",
        "print(\"Classification Report for Tuned KNN:\\n\", classification_report_knn_tuned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfcVpsvJ3_C_"
      },
      "source": [
        "##5. SVM (rbf, linear)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsLq5KNs5dkl"
      },
      "source": [
        "#SVM Accuracy (in %): 34.19%\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARt8YYtn49lG",
        "outputId": "894ff9db-bfe1-4b07-9076-c44359294004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy (in %): 34.19%\n",
            "Classification Report for SVM:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.35      1.00      0.51      1979\n",
            "           0       0.00      0.00      0.00        42\n",
            "           1       0.00      0.00      0.00        50\n",
            "           2       0.00      0.00      0.00        43\n",
            "           3       0.00      0.00      0.00        30\n",
            "           4       0.00      0.00      0.00        47\n",
            "           5       0.00      0.00      0.00        39\n",
            "           6       0.00      0.00      0.00        40\n",
            "           7       0.00      0.00      0.00        33\n",
            "           8       0.00      0.00      0.00        43\n",
            "           9       0.00      0.00      0.00        44\n",
            "          10       0.00      0.00      0.00        45\n",
            "          11       0.00      0.00      0.00        46\n",
            "          12       0.00      0.00      0.00        49\n",
            "          13       0.00      0.00      0.00        43\n",
            "          14       0.00      0.00      0.00        31\n",
            "          15       0.00      0.00      0.00        51\n",
            "          16       0.00      0.00      0.00        32\n",
            "          17       0.00      0.00      0.00        45\n",
            "          18       0.00      0.00      0.00        37\n",
            "          19       0.00      0.00      0.00        36\n",
            "          20       0.00      0.00      0.00        40\n",
            "          21       0.00      0.00      0.00        37\n",
            "          22       0.00      0.00      0.00        48\n",
            "          23       0.00      0.00      0.00        46\n",
            "          24       0.00      0.00      0.00        52\n",
            "          25       0.00      0.00      0.00        40\n",
            "          26       0.00      0.00      0.00        36\n",
            "          27       0.00      0.00      0.00        50\n",
            "          28       0.00      0.00      0.00        43\n",
            "          29       0.00      0.00      0.00        44\n",
            "          30       0.00      0.00      0.00        42\n",
            "          31       0.00      0.00      0.00        34\n",
            "          32       0.00      0.00      0.00        43\n",
            "          33       0.00      0.00      0.00        37\n",
            "          34       0.00      0.00      0.00        36\n",
            "          35       0.00      0.00      0.00        43\n",
            "          36       0.00      0.00      0.00        37\n",
            "          37       0.00      0.00      0.00        39\n",
            "          38       0.00      0.00      0.00        40\n",
            "          39       0.00      0.00      0.00        35\n",
            "          40       0.00      0.00      0.00        35\n",
            "          41       0.00      0.00      0.00        32\n",
            "          42       0.00      0.00      0.00        42\n",
            "          43       0.00      0.00      0.00        51\n",
            "          44       0.00      0.00      0.00        36\n",
            "          45       0.00      0.00      0.00        35\n",
            "          46       0.00      0.00      0.00        34\n",
            "          47       0.00      0.00      0.00        35\n",
            "          48       0.00      0.00      0.00        44\n",
            "          49       0.00      0.00      0.00        43\n",
            "          50       0.00      0.00      0.00        38\n",
            "          51       0.00      0.00      0.00        36\n",
            "          52       0.00      0.00      0.00        42\n",
            "          53       0.00      0.00      0.00        43\n",
            "          54       0.00      0.00      0.00        40\n",
            "          55       0.00      0.00      0.00        40\n",
            "          56       0.00      0.00      0.00        38\n",
            "          57       0.00      0.00      0.00        46\n",
            "          58       0.00      0.00      0.00        41\n",
            "          59       0.00      0.00      0.00        46\n",
            "          60       0.00      0.00      0.00        46\n",
            "          61       0.00      0.00      0.00        37\n",
            "          62       0.00      0.00      0.00        38\n",
            "          63       0.00      0.00      0.00        41\n",
            "          64       0.00      0.00      0.00        35\n",
            "          65       0.00      0.00      0.00        28\n",
            "          66       0.00      0.00      0.00        39\n",
            "          67       0.00      0.00      0.00        44\n",
            "          68       0.00      0.00      0.00        37\n",
            "          69       0.00      0.00      0.00        44\n",
            "          70       0.00      0.00      0.00        45\n",
            "          71       0.00      0.00      0.00        42\n",
            "          72       0.00      0.00      0.00        47\n",
            "          73       0.10      0.26      0.15        38\n",
            "          74       0.00      0.00      0.00        33\n",
            "          75       0.00      0.00      0.00        42\n",
            "          76       0.00      0.00      0.00        42\n",
            "          77       0.00      0.00      0.00        35\n",
            "          78       0.00      0.00      0.00        50\n",
            "          79       0.00      0.00      0.00        39\n",
            "          80       0.00      0.00      0.00        40\n",
            "          81       0.00      0.00      0.00        40\n",
            "          82       0.00      0.00      0.00        35\n",
            "          83       0.00      0.00      0.00        35\n",
            "          84       0.00      0.00      0.00        34\n",
            "          85       0.00      0.00      0.00        52\n",
            "          86       0.00      0.00      0.00        38\n",
            "          87       0.00      0.00      0.00        31\n",
            "          88       0.00      0.00      0.00        39\n",
            "          89       0.00      0.00      0.00        33\n",
            "          90       0.00      0.00      0.00        32\n",
            "          91       0.00      0.00      0.00        44\n",
            "          92       0.00      0.00      0.00        38\n",
            "          93       0.00      0.00      0.00        40\n",
            "          94       0.00      0.00      0.00        43\n",
            "\n",
            "    accuracy                           0.34      5800\n",
            "   macro avg       0.00      0.01      0.01      5800\n",
            "weighted avg       0.12      0.34      0.18      5800\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# SVM 모델 생성 및 훈련\n",
        "svm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale')  # rbf 커널 사용, C와 gamma 값은 예시입니다.\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# 모델 평가\n",
        "y_pred_svm = svm_classifier.predict(X_test)\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "classification_report_svm = classification_report(y_test, y_pred_svm)\n",
        "\n",
        "print(\"SVM Accuracy (in %): {:.2f}%\".format(accuracy_svm * 100))\n",
        "print(\"Classification Report for SVM:\\n\", classification_report_svm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WM3lZiP-UrX"
      },
      "source": [
        "#튜닝한 RGF SVM : 65.86%\n",
        "1)Best parameters: {'C': 100, 'gamma': 1}\n",
        "\n",
        "2)Tuned SVM Accuracy (in %): 65.86%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4_otcBD-PWq"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 데이터 스케일링\n",
        "scaler = StandardScaler()\n",
        "\n",
        "y_train = y_train.ravel()\n",
        "y_test = y_test.values.ravel()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# SVM 모델 생성\n",
        "svm_classifier = SVC()\n",
        "\n",
        "# 탐색할 매개변수 그리드 설정\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': ['scale', 'auto', 0.1, 1, 10]\n",
        "}\n",
        "\n",
        "# 그리드 서치를 사용하여 최적의 매개변수 찾기\n",
        "grid_search = GridSearchCV(svm_classifier, param_grid, cv=5)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 최적의 매개변수 출력\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# 최적의 매개변수로 모델 재훈련\n",
        "best_C = grid_search.best_params_['C']\n",
        "best_gamma = grid_search.best_params_['gamma']\n",
        "svm_classifier_tuned = SVC(C=best_C, gamma=best_gamma)\n",
        "svm_classifier_tuned.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 튜닝된 모델 평가\n",
        "y_pred_tuned = svm_classifier_tuned.predict(X_test_scaled)\n",
        "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
        "print(\"Tuned SVM Accuracy (in %): {:.2f}%\".format(accuracy_tuned * 100))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 데이터 스케일링\n",
        "scaler = StandardScaler()\n",
        "\n",
        "y_train = y_train.values.ravel()\n",
        "y_test = y_test.values.ravel()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 최적의 하이퍼파라미터로 새로운 SVM 모델 생성\n",
        "best_C = 100\n",
        "best_gamma = 1\n",
        "svm_classifier_tuned = SVC(C=best_C, gamma=best_gamma)\n",
        "svm_classifier_tuned.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 튜닝된 모델 평가\n",
        "y_pred_tuned = svm_classifier_tuned.predict(X_test_scaled)\n",
        "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
        "print(\"Tuned SVM Accuracy (in %): {:.2f}%\".format(accuracy_tuned * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFC5RwBH9Qaf",
        "outputId": "6822827e-9ad2-4a2d-8058-e48ee9e08f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuned SVM Accuracy (in %): 68.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_tuned = svm_classifier_tuned.predict(X_test_scaled)\n",
        "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
        "print(\"Tuned SVM Accuracy (in %): {:.2f}%\".format(accuracy_tuned * 100))\n",
        "\n",
        "# Classification Report 출력\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_tuned))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIidayFCD5G0",
        "outputId": "06ee5166-2bb7-43c1-e64d-b3e830574217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuned SVM Accuracy (in %): 68.31%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.77      0.88      0.82      2058\n",
            "           0       0.59      0.49      0.53        41\n",
            "           1       0.43      0.43      0.43        35\n",
            "           2       0.60      0.72      0.65        43\n",
            "           3       0.70      0.46      0.56        41\n",
            "           4       0.72      0.64      0.67        44\n",
            "           5       0.64      0.45      0.53        40\n",
            "           6       0.73      0.87      0.79        31\n",
            "           7       0.69      0.79      0.73        42\n",
            "           8       0.76      0.74      0.75        43\n",
            "           9       0.56      0.51      0.54        37\n",
            "          10       0.72      0.42      0.53        43\n",
            "          11       0.48      0.53      0.51        30\n",
            "          12       0.79      0.79      0.79        42\n",
            "          13       0.34      0.35      0.35        37\n",
            "          14       0.52      0.43      0.47        35\n",
            "          15       0.50      0.48      0.49        33\n",
            "          16       0.69      0.51      0.59        39\n",
            "          17       0.46      0.48      0.47        33\n",
            "          18       0.92      0.78      0.85        46\n",
            "          19       0.26      0.21      0.23        43\n",
            "          20       0.94      0.96      0.95        51\n",
            "          21       0.62      0.21      0.31        48\n",
            "          22       0.45      0.43      0.44        42\n",
            "          23       0.76      0.76      0.76        29\n",
            "          24       0.44      0.27      0.33        56\n",
            "          25       0.70      0.47      0.56        45\n",
            "          26       0.69      0.86      0.76        43\n",
            "          27       0.43      0.38      0.41        34\n",
            "          28       0.70      0.70      0.70        37\n",
            "          29       0.62      0.67      0.64        39\n",
            "          30       0.76      0.71      0.73        41\n",
            "          31       0.75      0.64      0.69        56\n",
            "          32       0.71      0.72      0.72        40\n",
            "          33       0.60      0.70      0.65        43\n",
            "          34       0.15      0.16      0.16        31\n",
            "          35       0.74      0.76      0.75        42\n",
            "          36       0.62      0.64      0.63        44\n",
            "          37       0.48      0.46      0.47        35\n",
            "          38       0.68      0.76      0.72        34\n",
            "          39       0.64      0.58      0.61        43\n",
            "          40       0.48      0.36      0.41        39\n",
            "          41       0.82      0.72      0.77        39\n",
            "          42       0.40      0.53      0.46        40\n",
            "          43       0.88      0.86      0.87        44\n",
            "          44       0.78      0.97      0.87        37\n",
            "          45       0.33      0.23      0.27        44\n",
            "          46       0.59      0.59      0.59        41\n",
            "          47       0.43      0.33      0.38        30\n",
            "          48       0.52      0.30      0.38        46\n",
            "          49       0.63      0.79      0.70        28\n",
            "          50       0.68      0.80      0.74        40\n",
            "          51       0.43      0.31      0.36        32\n",
            "          52       0.66      0.41      0.51        46\n",
            "          53       0.59      0.45      0.51        51\n",
            "          54       0.50      0.46      0.48        35\n",
            "          55       0.41      0.36      0.38        42\n",
            "          56       0.81      0.81      0.81        42\n",
            "          57       0.76      0.71      0.73        41\n",
            "          58       0.68      0.72      0.70        39\n",
            "          59       0.68      0.61      0.64        44\n",
            "          60       0.78      0.60      0.68        48\n",
            "          61       0.54      0.44      0.48        34\n",
            "          62       0.67      0.72      0.69        36\n",
            "          63       0.52      0.34      0.41        41\n",
            "          64       0.55      0.52      0.53        44\n",
            "          65       0.64      0.55      0.59        38\n",
            "          66       0.43      0.57      0.49        37\n",
            "          67       0.56      0.81      0.67        27\n",
            "          68       0.42      0.31      0.36        35\n",
            "          69       0.51      0.47      0.49        45\n",
            "          70       0.90      0.95      0.93        40\n",
            "          71       0.63      0.44      0.52        39\n",
            "          72       0.60      0.52      0.56        29\n",
            "          73       0.48      0.77      0.59        30\n",
            "          74       0.52      0.52      0.52        33\n",
            "          75       0.90      0.93      0.92        41\n",
            "          76       0.88      0.88      0.88        41\n",
            "          77       0.43      0.37      0.40        35\n",
            "          78       0.39      0.29      0.33        38\n",
            "          79       0.51      0.46      0.49        39\n",
            "          80       0.66      0.74      0.70        42\n",
            "          81       0.40      0.34      0.37        41\n",
            "          82       0.60      0.45      0.51        40\n",
            "          83       0.71      0.68      0.69        40\n",
            "          84       0.62      0.68      0.65        37\n",
            "          85       0.70      0.78      0.74        40\n",
            "          86       0.90      0.83      0.86        46\n",
            "          87       0.70      0.70      0.70        37\n",
            "          88       0.63      0.42      0.51        40\n",
            "          89       0.41      0.40      0.41        35\n",
            "          90       0.69      0.63      0.66        35\n",
            "          91       0.73      0.66      0.69        41\n",
            "          92       0.76      0.43      0.55        30\n",
            "          93       0.79      0.79      0.79        42\n",
            "          94       0.46      0.34      0.39        35\n",
            "\n",
            "    accuracy                           0.68      5800\n",
            "   macro avg       0.62      0.58      0.59      5800\n",
            "weighted avg       0.67      0.68      0.67      5800\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tXoxjyK5zhM"
      },
      "source": [
        "##2) Linear SVM: 0.11137931034482759\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gap_ha2z5vha",
        "outputId": "418e5347-0b80-4db9-9e75-11cb96b151f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Linear SVM: 0.011206896551724138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 선형 커널 SVM 모델 학습 및 평가\n",
        "svm_linear = LinearSVC(C=10000, loss='hinge')\n",
        "svm_linear.fit(X_train, y_train)\n",
        "y_pred_linear = svm_linear.predict(X_test)\n",
        "accuracy_linear = accuracy_score(y_test, y_pred_linear)\n",
        "print(\"Accuracy of Linear SVM:\", accuracy_linear)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlcNL91I-4Vr"
      },
      "source": [
        "#튜닝한 Linear SVM\n",
        "\n",
        "1) y = column_or_1d(y, warn=True)\n",
        "\n",
        "Best Parameters: {'C': 1, 'loss': 'hinge'}\n",
        "\n",
        "Best Cross-Validation Accuracy: 0.14439655172413796\n",
        "\n",
        "Test Set Accuracy of Best Model: 0.010689655172413793"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EGubuI6-9rR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06e610ca-b1f5-49b6-f17c-ab94b9fd56cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 1, 'loss': 'hinge'}\n",
            "Best Cross-Validation Accuracy: 0.14439655172413796\n",
            "Test Set Accuracy of Best Model: 0.010689655172413793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 탐색할 매개변수 그리드 정의\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'loss': ['hinge', 'squared_hinge']}\n",
        "\n",
        "# SVC 모델 객체 생성\n",
        "svm = LinearSVC()\n",
        "\n",
        "# GridSearchCV 객체 생성 및 훈련 데이터에 대해 그리드 탐색 수행\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 하이퍼파라미터와 그 때의 정확도 출력\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# 최적의 모델에 대해 테스트 세트로 성능 평가\n",
        "best_svm = grid_search.best_estimator_\n",
        "test_accuracy = best_svm.score(X_test, y_test)\n",
        "print(\"Test Set Accuracy of Best Model:\", test_accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}